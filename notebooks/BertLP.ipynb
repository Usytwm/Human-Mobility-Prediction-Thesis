{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvBqrhndc9Gj",
        "outputId": "e4c43d4c-591a-4e95-869e-18afef14015a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'calc_dtw', 'calc_dtw_orig', 'calc_dtw_single', 'calc_geobleu', 'calc_geobleu_orig', 'calc_geobleu_single', 'seq_eval']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer,BertModel, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import LongformerTokenizer, LongformerModel\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "SMALL_DATASET = False\n",
        "ROUTE = \"/content/drive/MyDrive/Data/cityA_groundtruthdata_small.csv\" if SMALL_DATASET else \"/content/drive/MyDrive/Data/cityA_groundtruthdata_first_3000_users.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dlEvGmngrRuw",
        "outputId": "fb8b23cf-aab9-4b7a-9f1c-07460413b813"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-44bc25a6-bbb7-4adf-befb-6f6c556fc2df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>d</th>\n",
              "      <th>t</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>75</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>76</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>81</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>13</td>\n",
              "      <td>86</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>85</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44bc25a6-bbb7-4adf-befb-6f6c556fc2df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44bc25a6-bbb7-4adf-befb-6f6c556fc2df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44bc25a6-bbb7-4adf-befb-6f6c556fc2df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e490458-a51f-4f67-947e-71397d65bd0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e490458-a51f-4f67-947e-71397d65bd0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e490458-a51f-4f67-947e-71397d65bd0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   uid   d   t   x   y\n",
              "0    0   0  25  75  82\n",
              "1    0   0  24  76  86\n",
              "2    0   0  22  81  89\n",
              "3    0  18  13  86  97\n",
              "4    0  18  12  85  97"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(ROUTE)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsBZC51OsFsE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def get_scaler(df: pd.DataFrame, columns: list):\n",
        "    \"\"\"\n",
        "    Ajusta un MinMaxScaler a las columnas especificadas del DataFrame y devuelve el scaler.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con los datos originales.\n",
        "        columns (list): Lista de nombres de columnas a normalizar.\n",
        "\n",
        "    Returns:\n",
        "        scaler: Instancia ajustada de MinMaxScaler.\n",
        "    \"\"\"\n",
        "    # Crear un scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Ajustar el scaler a las columnas especificadas\n",
        "    scaler.fit(df[columns])\n",
        "    return scaler\n",
        "\n",
        "def normalize_data(df: pd.DataFrame, scaler: MinMaxScaler, columns: list):\n",
        "    \"\"\"\n",
        "    Normaliza las columnas especificadas de un DataFrame utilizando un MinMaxScaler ya ajustado.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con los datos originales.\n",
        "        scaler (MinMaxScaler): Scaler ajustado con los datos de entrenamiento.\n",
        "        columns (list): Lista de nombres de columnas a normalizar.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame normalizado\n",
        "    \"\"\"\n",
        "    # Transformar las columnas especificadas con el scaler ajustado\n",
        "    df[columns] = scaler.transform(df[columns])\n",
        "    return df\n",
        "def inverse_transform_predictions(predictions, scaler: MinMaxScaler, columns_to_desnormalize):\n",
        "    \"\"\"\n",
        "    Desnormaliza las predicciones del modelo usando el scaler ajustado.\n",
        "\n",
        "    Args:\n",
        "        predictions (torch.Tensor or np.ndarray): Predicciones normalizadas con forma (batch_size, sequence_length, num_features) o (sequence_length, num_features).\n",
        "        scaler (MinMaxScaler): Scaler ajustado con los datos de entrada.\n",
        "        columns_to_desnormalize (list): √çndices de las columnas a desnormalizar (por ejemplo, [0, 1] para x, y).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Predicciones desnormalizadas con la misma forma que las predicciones originales.\n",
        "    \"\"\"\n",
        "    # Si es un tensor de PyTorch, convi√©rtelo a un numpy array\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "    # Si las predicciones tienen solo 2 dimensiones, agregar una dimensi√≥n de batch\n",
        "    if predictions.ndim == 2:  # (sequence_length, num_features)\n",
        "        predictions = predictions[np.newaxis, :, :]  # (1, sequence_length, num_features)\n",
        "\n",
        "    batch_size, sequence_length, num_features = predictions.shape\n",
        "\n",
        "    # Crear un array desnormalizado con la misma forma que las predicciones\n",
        "    desnormalized = np.zeros_like(predictions)\n",
        "\n",
        "    # Desnormalizar cada elemento del batch\n",
        "    for i in range(batch_size):\n",
        "        # Extraer la predicci√≥n del batch actual (sequence_length, num_features)\n",
        "        single_prediction = predictions[i]\n",
        "\n",
        "        # Crear una matriz con el mismo n√∫mero de columnas que el scaler original\n",
        "        full_array = np.zeros((sequence_length, scaler.n_features_in_))\n",
        "\n",
        "        # Insertar las predicciones en las columnas correspondientes\n",
        "        full_array[:, columns_to_desnormalize] = single_prediction\n",
        "\n",
        "        # Aplicar la transformaci√≥n inversa\n",
        "        full_array = scaler.inverse_transform(full_array)\n",
        "\n",
        "        # Extraer las columnas desnormalizadas correspondientes\n",
        "        desnormalized[i] = full_array[:, columns_to_desnormalize]\n",
        "\n",
        "    return desnormalized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw0D2GvQdw-l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def fill_missing_data(df: pd.DataFrame, padding_value=-1) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Rellena los datos faltantes asegurando 48 timeslots por d√≠a por usuario.\n",
        "    - Primero calcula `delta_t` en los datos originales antes de rellenar.\n",
        "    - Luego, completa los timeslots faltantes y asigna `padding_value` a `delta_t` en las filas agregadas.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con datos originales ['uid', 'd', 't', 'x', 'y'].\n",
        "        padding_value (int): Valor de padding para coordenadas y `delta_t` en filas agregadas.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Datos completos con padding en `delta_t`, `x`, `y` y normalizaci√≥n aplicada.\n",
        "    \"\"\"\n",
        "\n",
        "    df[\"delta_t\"] = df.groupby([\"uid\", \"d\"])[\"t\"].diff().astype(float)\n",
        "    df[\"delta_t\"] = df[\"delta_t\"].fillna(0)  # El primer valor del d√≠a tendr√° `delta_t = 0`\n",
        "\n",
        "    uids = df[\"uid\"].unique()\n",
        "    days = np.arange(df[\"d\"].min(), df[\"d\"].max() + 1)\n",
        "    timeslots = np.arange(48)  # 48 timeslots por d√≠a\n",
        "\n",
        "    complete_index = pd.MultiIndex.from_product([uids, days, timeslots], names=[\"uid\", \"d\", \"t\"])\n",
        "    complete_df = pd.DataFrame(index=complete_index).reset_index()\n",
        "\n",
        "    df = pd.merge(complete_df, df, on=[\"uid\", \"d\", \"t\"], how=\"left\")\n",
        "\n",
        "    df[\"day_of_week\"] = df[\"d\"] % 7\n",
        "\n",
        "    df[\"delta_t\"] = df[\"delta_t\"].fillna(padding_value)\n",
        "\n",
        "    df[\"x\"] = df[\"x\"].fillna(padding_value)\n",
        "    df[\"y\"] = df[\"y\"].fillna(padding_value)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5huTvMxUd3aG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def create_sequences(data, days=7, timestep_per_day=48, padding_value=0):\n",
        "    \"\"\"\n",
        "    Genera ventanas de entrada (7 d√≠as previos) y salida (7 d√≠as siguientes),\n",
        "    asegurando padding en coordenadas faltantes.\n",
        "\n",
        "    Returns:\n",
        "        Arrays con secuencias y m√°scaras de padding con las dimensiones correctas.\n",
        "    \"\"\"\n",
        "    window_size = days * timestep_per_day\n",
        "    inputs, outputs, mask_inputs, mask_outputs = [], [], [], []\n",
        "\n",
        "    for uid in data[\"uid\"].unique():\n",
        "        user_data = data[data[\"uid\"] == uid]\n",
        "\n",
        "        for start_idx in range(0, len(user_data) - 2 * window_size, timestep_per_day):\n",
        "            input_seq = user_data.iloc[start_idx:start_idx + window_size]\n",
        "            output_seq = user_data.iloc[start_idx + window_size:start_idx + 2 * window_size]\n",
        "\n",
        "            # M√°scaras de valores reales\n",
        "            mask_input_seq = np.where((input_seq[\"x\"] == padding_value) & (input_seq[\"y\"] == padding_value), 0, 1)\n",
        "            mask_output_seq = np.where((output_seq[\"x\"] == padding_value) & (output_seq[\"y\"] == padding_value), 0, 1)\n",
        "\n",
        "            # **Corregir `outputs` y `mask_outputs` para que tengan la forma correcta (336, 2)**\n",
        "            inputs.append(input_seq[[\"d\", \"t\", \"x\", \"y\", \"day_of_week\", \"delta_t\"]].values.tolist())\n",
        "            outputs.append(output_seq[[\"x\", \"y\"]].values.tolist())  # ‚úÖ  forma (336, 2)\n",
        "            mask_inputs.append(np.tile(mask_input_seq.reshape(-1, 1), (1, 2)).tolist())\n",
        "            mask_outputs.append(np.tile(mask_output_seq.reshape(-1, 1), (1, 2)).tolist())  # Expande a (336, 2)\n",
        "\n",
        "    return np.array(inputs), np.array(mask_inputs), np.array(outputs), np.array(mask_outputs)\n",
        "\n",
        "def split_data(df: pd.DataFrame) -> tuple:\n",
        "    \"\"\"\n",
        "    Divide los datos en entrenamiento, validaci√≥n y prueba, asegurando 15 d√≠as adicionales\n",
        "    para las secuencias de validaci√≥n y prueba.\n",
        "    \"\"\"\n",
        "    # Entrenamiento: datos antes del d√≠a 44\n",
        "    train = df[df[\"d\"] < 44]\n",
        "\n",
        "    # Validaci√≥n: incluye d√≠as desde el 37 (44 - 7) para construir las secuencias\n",
        "    val = df[(df[\"d\"] >= 37) & (df[\"d\"] < 59)]\n",
        "\n",
        "    # Prueba: incluye d√≠as desde el 52 (59 - 7) para construir las secuencias\n",
        "    test = df[df[\"d\"] >= 52]\n",
        "\n",
        "    return train.copy(), val.copy(), test.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11vL9sfappZ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MobilityDataset(Dataset):\n",
        "    def __init__(self, X, mask_X, Y, mask_Y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.mask_X = torch.tensor(mask_X, dtype=torch.int)\n",
        "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
        "        self.mask_Y = torch.tensor(mask_Y, dtype=torch.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.mask_X[idx], self.Y[idx], self.mask_Y[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVconsg8tR1m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def build_dataloaders(df, batch_size=32, padding_value=-1,columns=['x','y','delta_t'], shuffle=True):\n",
        "    \"\"\"\n",
        "    Preprocesa los datos, normaliza, genera secuencias y devuelve DataLoaders listos para entrenar.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con datos crudos.\n",
        "        batch_size (int): Tama√±o del batch para entrenamiento.\n",
        "        padding_value (tuple): Valor usado para rellenar coordenadas faltantes.\n",
        "        shuffle (bool): Si se deben mezclar los datos en el DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_loader, val_loader, test_loader)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöÄ Llenando datos faltantes y normalizando...\")\n",
        "    df_filled = fill_missing_data(df, padding_value)\n",
        "\n",
        "    # **Dividir en Train, Validation y Test**\n",
        "    train_df, val_df, test_df = split_data(df_filled)\n",
        "\n",
        "    scaler = get_scaler(train_df, columns)\n",
        "\n",
        "    # Normalizar los datos solamnete con l scaler del train\n",
        "    train_data = normalize_data(train_df, scaler, columns)\n",
        "    val_data = normalize_data(val_df, scaler, columns)\n",
        "    test_data = normalize_data(test_df, scaler, columns)\n",
        "    # display(train_data.head(100))\n",
        "    # display(val_data.head(100))\n",
        "    # display(test_data.head(300))\n",
        "\n",
        "    print(\"üìä Generando secuencias...\")\n",
        "    X_train, mask_X_train, Y_train, mask_Y_train = create_sequences(train_data)\n",
        "    print(\"üìä Creada secuencia de entrenamineto\")\n",
        "    X_val, mask_X_val, Y_val, mask_Y_val = create_sequences(val_data)\n",
        "    print(\"üìä Creada secuencia de validaci√≥n\")\n",
        "    X_test, mask_X_test, Y_test, mask_Y_test = create_sequences(test_data)\n",
        "    print(\"üìä Creada secuencia de testing\")\n",
        "\n",
        "    print(\"üîÑ Creando datasets...\")\n",
        "    train_dataset = MobilityDataset(X_train, mask_X_train, Y_train, mask_Y_train)\n",
        "    val_dataset = MobilityDataset(X_val, mask_X_val, Y_val, mask_Y_val)\n",
        "    test_dataset = MobilityDataset(X_test, mask_X_test, Y_test, mask_Y_test)\n",
        "\n",
        "    ### **4Ô∏è‚É£ Creaci√≥n de DataLoaders**\n",
        "    print(\"üì¶ Creando DataLoaders...\")\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(\"‚úÖ DataLoaders listos para entrenamiento.\")\n",
        "    return train_loader, val_loader, test_loader, scaler, test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_VO-PhtcDW",
        "outputId": "c327c037-a757-4b69-d940-3ee919789c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Llenando datos faltantes y normalizando...\n",
            "üìä Generando secuencias...\n",
            "üìä Creada secuencia de entrenamineto\n",
            "üìä Creada secuencia de validaci√≥n\n",
            "üìä Creada secuencia de testing\n",
            "üîÑ Creando datasets...\n",
            "üì¶ Creando DataLoaders...\n",
            "‚úÖ DataLoaders listos para entrenamiento.\n"
          ]
        }
      ],
      "source": [
        "# Construir DataLoaders\n",
        "train_loader, val_loader, test_loader, scaler, test_data = build_dataloaders(df, batch_size=32,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwAhY3eQqSaf"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class LP_BERT(nn.Module):\n",
        "    def __init__(self, num_dates, num_timeslots, num_dayofweek, embed_dim_cat=32, hidden_dim=768, output_days=7, timeslots_per_day=48):\n",
        "        super(LP_BERT, self).__init__()\n",
        "\n",
        "        # Embeddings para variables categ√≥ricas\n",
        "        self.date_embedding = nn.Embedding(num_dates, embed_dim_cat)\n",
        "        self.timeslot_embedding = nn.Embedding(num_timeslots, embed_dim_cat)\n",
        "        self.dayofweek_embedding = nn.Embedding(num_dayofweek, embed_dim_cat)\n",
        "\n",
        "        # Proyecci√≥n para variables continuas\n",
        "        self.delta_t_projection = nn.Linear(1, embed_dim_cat)\n",
        "        self.location_projection = nn.Linear(2, embed_dim_cat)\n",
        "\n",
        "        # Normalizaci√≥n antes de la entrada a BERT\n",
        "        self.layer_norm = nn.LayerNorm(embed_dim_cat)\n",
        "\n",
        "        # Capa de proyecci√≥n final antes de la entrada a BERT\n",
        "        self.token_projection = nn.Linear(embed_dim_cat, hidden_dim)\n",
        "\n",
        "        # Modelo BERT preentrenado\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        # Capa de salida para predecir 7 d√≠as x 48 timeslots x 2 coordenadas\n",
        "        self.output_size = output_days * timeslots_per_day * 2\n",
        "        self.regressor = nn.Linear(hidden_dim, self.output_size)\n",
        "\n",
        "    def forward(self, X, mask_X):\n",
        "        \"\"\"\n",
        "        - X: Entrada en formato (batch_size, seq_length, feature_dim).\n",
        "        - mask_X: M√°scara de atenci√≥n indicando qu√© valores son reales y cu√°les padding.\n",
        "\n",
        "        Retorna:\n",
        "        - pred_coords: Predicci√≥n de coordenadas (batch_size, 336, 2).\n",
        "        \"\"\"\n",
        "        batch_size, seq_length, feature_dim = X.shape  #  Ahora manejamos correctamente la forma\n",
        "\n",
        "        # Extraer los valores desde X\n",
        "        date = X[:, :, 0].long()\n",
        "        timeslot = X[:, :, 1].long()\n",
        "        location = X[:, :, 2:4].float()\n",
        "        day_of_week = X[:, :, 4].long()\n",
        "        delta_t = X[:, :, 5].float().unsqueeze(-1)  # (batch_size, seq_length, 1)\n",
        "\n",
        "        # Obtener embeddings para variables categ√≥ricas\n",
        "        emb_date = self.date_embedding(date)\n",
        "        emb_timeslot = self.timeslot_embedding(timeslot)\n",
        "        emb_dayofweek = self.dayofweek_embedding(day_of_week)\n",
        "\n",
        "        # Proyecci√≥n de variables continuas\n",
        "        emb_delta_t = self.delta_t_projection(delta_t)\n",
        "        emb_location = self.location_projection(location)\n",
        "\n",
        "        # Add & Norm antes de BERT\n",
        "        token_emb = emb_date + emb_timeslot + emb_dayofweek + emb_delta_t + emb_location\n",
        "        token_emb = self.layer_norm(token_emb)\n",
        "\n",
        "        # Proyectar al espacio hidden\n",
        "        token_emb = self.token_projection(token_emb)\n",
        "\n",
        "        # Usar mask_X como atenci√≥n para BERT\n",
        "        attention_mask = mask_X[:, :, 0].long()  # Seleccionamos solo una dimensi√≥n (batch_size, 336)\n",
        "\n",
        "        # display(attention_mask.shape)\n",
        "\n",
        "        # Pasar por BERT\n",
        "        outputs = self.bert(inputs_embeds=token_emb, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Predicci√≥n de coordenadas futuras\n",
        "        pred_coords = self.regressor(cls_output)\n",
        "        return pred_coords.view(-1, 336, 2)  # 336 = 7 d√≠as * 48 timeslots * 2 coordenadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbGRMI9aqcJL"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def train_step(model, optimizer, batch, device):\n",
        "    \"\"\"\n",
        "    Realiza un paso de entrenamiento con los datos organizados en X y mask_X.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    X, mask_X, target, mask_target = batch\n",
        "\n",
        "    X = X.to(device)\n",
        "    mask_X = mask_X.to(device)\n",
        "    target = target.to(device)\n",
        "    mask_target = mask_target.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    pred_location = model(X, mask_X)\n",
        "    # display(pred_location.shape)\n",
        "    # display(target.shape)\n",
        "    # display(mask_target.shape)\n",
        "\n",
        "    valid_values = mask_target.sum()  # Cuenta cu√°ntos valores son realmente v√°lidos\n",
        "    loss = (F.mse_loss(pred_location * mask_target, target * mask_target, reduction='sum') / valid_values)\n",
        "\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-15jkmyspUK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def evaluate_model(model, val_loader, device):\n",
        "    \"\"\"\n",
        "    Eval√∫a el modelo en el conjunto de validaci√≥n con UNA SOLA BARRA de progreso.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(val_loader, desc=f\"üîµ Validating...\", position=0, leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            X, mask_X, target, mask_target = batch\n",
        "            X, mask_X, target, mask_target = X.to(device), mask_X.to(device), target.to(device), mask_target.to(device)\n",
        "\n",
        "            pred_location = model(X, mask_X)\n",
        "            valid_values = mask_target.sum()  # Cuenta cu√°ntos valores son realmente v√°lidos\n",
        "            loss = (F.mse_loss(pred_location * mask_target, target * mask_target, reduction='sum') / valid_values)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / (progress_bar.n + 1)\n",
        "            progress_bar.set_postfix(val_loss=f\"{avg_loss:.4f}\")\n",
        "\n",
        "    progress_bar.close()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, device, epochs=5):\n",
        "    \"\"\"\n",
        "    Entrena el modelo con una barra de entrenamiento que se oculta al validar.\n",
        "    Despu√©s de cada validaci√≥n, muestra el historial de entrenamiento y sigue.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    history = []\n",
        "\n",
        "    total_steps = epochs * len(train_loader)\n",
        "    progress_bar = tqdm(total=total_steps, desc=\"üü¢ Training Progress\", position=0, leave=False)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            loss = train_step(model, optimizer, batch, device)\n",
        "            total_loss += loss\n",
        "\n",
        "            current_progress = (epoch - 1) + ((batch_idx + 1) / len(train_loader))\n",
        "            progress_bar.set_description(f\"üü¢ Epoch {current_progress:.1f}/{epochs}\")\n",
        "            progress_bar.set_postfix(epoch=f\"{epoch}/{epochs}\", train_loss=f\"{total_loss / (batch_idx + 1):.4f}\")\n",
        "            progress_bar.update(1)\n",
        "\n",
        "        val_loss = evaluate_model(model, val_loader, device)\n",
        "\n",
        "        history.append({\"Epoch\": epoch, \"Train Loss\": total_loss / len(train_loader), \"Val Loss\": val_loss})\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        history_df = pd.DataFrame(history)\n",
        "        display(history_df)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Cargar los mejores pesos\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    progress_bar.close()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "G5q_AJC3q52d",
        "outputId": "f1b955c1-43df-4946-9c3a-3ec98cc3d038"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"model = train_model(model, train_loader, val_loader, optimizer, device, epochs=epochs)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013718830315608617,\n        \"min\": 0.04512337918588319,\n        \"max\": 0.04967644115660964,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.04519615168131158,\n          0.04661875078752584,\n          0.04542497073317896\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004844133919615275,\n        \"min\": 0.04539997961682578,\n        \"max\": 0.04673952021884421,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.04545410753972828,\n          0.04661031205952167,\n          0.045578293872997167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a224a334-1584-48a1-841b-9c3294cd107a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Val Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.049676</td>\n",
              "      <td>0.046740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.046619</td>\n",
              "      <td>0.046610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.046044</td>\n",
              "      <td>0.045971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.045732</td>\n",
              "      <td>0.045898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.045553</td>\n",
              "      <td>0.045608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.045425</td>\n",
              "      <td>0.045578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0.045345</td>\n",
              "      <td>0.045532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.045231</td>\n",
              "      <td>0.045479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.045196</td>\n",
              "      <td>0.045454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.045123</td>\n",
              "      <td>0.045400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a224a334-1584-48a1-841b-9c3294cd107a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a224a334-1584-48a1-841b-9c3294cd107a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a224a334-1584-48a1-841b-9c3294cd107a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-daa420b7-3927-45b8-bba1-b580d4b8280f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-daa420b7-3927-45b8-bba1-b580d4b8280f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-daa420b7-3927-45b8-bba1-b580d4b8280f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Epoch  Train Loss  Val Loss\n",
              "0      1    0.049676  0.046740\n",
              "1      2    0.046619  0.046610\n",
              "2      3    0.046044  0.045971\n",
              "3      4    0.045732  0.045898\n",
              "4      5    0.045553  0.045608\n",
              "5      6    0.045425  0.045578\n",
              "6      7    0.045345  0.045532\n",
              "7      8    0.045231  0.045479\n",
              "8      9    0.045196  0.045454\n",
              "9     10    0.045123  0.045400"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "# Configurar y entrenar el modelo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LP_BERT(num_dates=70, num_timeslots=48, num_dayofweek=7)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "epochs =10\n",
        "\n",
        "model = train_model(model, train_loader, val_loader, optimizer, device, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzFok1xC8M38",
        "outputId": "e399aa3e-bd83-4680-b606-d136b3ea03a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "üîµ Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [01:31<00:00,  8.20it/s, val_loss=0.0454]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "üîµ Validating...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 844/844 [01:42<00:00,  8.21it/s, val_loss=0.0450]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "val_loss = evaluate_model(model, val_loader, device)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "val_test = evaluate_model(model, test_loader, device)\n",
        "print(f\"Test Loss: {val_test:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EUsYRpultxlF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_metrics_sequence_bert(\n",
        "    test_loader, model, scaler, device\n",
        "):\n",
        "    \"\"\"\n",
        "    Eval√∫a las m√©tricas basadas en predicciones generadas por `LP_BERT` para un batch de test.\n",
        "\n",
        "    Args:\n",
        "        test_loader (DataLoader): DataLoader de prueba que contiene `X, mask_X, Y, mask_Y`.\n",
        "        model (nn.Module): Modelo LP_BERT entrenado.\n",
        "        scaler (MinMaxScaler): Scaler para normalizaci√≥n/desnormalizaci√≥n.\n",
        "        device (torch.device): Dispositivo donde se ejecutar√° el modelo.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (`generated_sequences`, `reference_sequences`) en formato `(d, t, x, y)`.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            X, mask_X, target, mask_target = batch\n",
        "            X, mask_X, target, mask_target = X.to(device), mask_X.to(device), target.to(device), mask_target.to(device)\n",
        "\n",
        "            pred_location = model(X, mask_X)\n",
        "            valid_values = mask_target.sum() \n",
        "            loss = (F.mse_loss(pred_location * mask_target, target * mask_target, reduction='sum') / valid_values)\n",
        "\n",
        "            print(f\"Test Loss: {loss.item():.4f}\")\n",
        "            break  \n",
        "\n",
        "    generated_sequences = []\n",
        "    reference_sequences = []\n",
        "\n",
        "    times_per_day = 48\n",
        "    current_day = 52\n",
        "    current_timeslot = 0\n",
        "    n_columns = scaler.n_features_in_\n",
        "\n",
        "    for step_idx, (x_pred, y_pred) in enumerate(pred_location[0].cpu().numpy()):  # Tomamos solo el primer sample del batch\n",
        "        if mask_target[0][step_idx].sum() > 0:  # Solo incluir valores v√°lidos (sin padding)\n",
        "            day_offset = current_timeslot // times_per_day\n",
        "            d = current_day + day_offset\n",
        "            t = current_timeslot % times_per_day\n",
        "\n",
        "            x_true, y_true = target[0][step_idx].cpu().numpy()\n",
        "\n",
        "            features_array = np.zeros(n_columns)\n",
        "            features_array[0] = x_true  # `x`\n",
        "            features_array[1] = y_true  # `y`\n",
        "\n",
        "            # üîπ Desnormalizar y redondear a enteros\n",
        "            target_desnormalized = scaler.inverse_transform([features_array])\n",
        "            x_true_desnormalized, y_true_desnormalized = np.round(target_desnormalized[0][:2]).astype(int)\n",
        "\n",
        "            features_array_pred = np.zeros(n_columns)\n",
        "            features_array_pred[0] = x_pred  # `x`\n",
        "            features_array_pred[1] = y_pred  # `y`\n",
        "\n",
        "            # üîπ Desnormalizar y redondear a enteros\n",
        "            predictions_desnormalized = scaler.inverse_transform([features_array_pred])\n",
        "            x_pred_desnormalized, y_pred_desnormalized = np.round(predictions_desnormalized[0][:2]).astype(int)\n",
        "\n",
        "            reference_sequences.append((d, t, x_true_desnormalized, y_true_desnormalized))\n",
        "            generated_sequences.append((d, t, x_pred_desnormalized, y_pred_desnormalized))\n",
        "\n",
        "        current_timeslot += 1\n",
        "\n",
        "    return generated_sequences, reference_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBjG_2lsyEVr",
        "outputId": "365da3c8-5a3a-4f2c-e0fe-ddbd2ff2d4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0294\n"
          ]
        }
      ],
      "source": [
        "# Evaluar en una muestra del test set\n",
        "generated_sequences, reference_sequences = evaluate_metrics_sequence_bert(\n",
        "    val_loader, model, scaler, device\n",
        ")\n",
        "# print(\"generated\")\n",
        "# display(generated_sequences)\n",
        "# print(\"reference\")\n",
        "# display(reference_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KJhxl8jayo2z"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import geobleu\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Metric(ABC):\n",
        "    \"\"\"\n",
        "    Clase base abstracta para diferentes m√©tricas.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def calculate(self, predictions, validation):\n",
        "        \"\"\"\n",
        "        Calcula el puntaje de la m√©trica basada en las predicciones y los datos de validaci√≥n.\n",
        "\n",
        "        Args:\n",
        "            predictions: Los datos predichos.\n",
        "            validation: Los datos de validaci√≥n.\n",
        "\n",
        "        Returns:\n",
        "            El puntaje calculado.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class LPPMetric(Metric):\n",
        "    \"\"\"\n",
        "    M√©trica para calcular la Precisi√≥n de Predicci√≥n de Ubicaci√≥n (LPP).\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate(self, predictions, validation):\n",
        "        return calculate_lpp(validation, predictions)\n",
        "\n",
        "\n",
        "class MAEMetric(Metric):\n",
        "    \"\"\"\n",
        "    M√©trica para calcular el Error Medio Absoluto (MAE).\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate(self, predictions_per_user, validation_per_user):\n",
        "        return calculate_error_metrics(predictions_per_user, validation_per_user)[\"MAE\"]\n",
        "\n",
        "\n",
        "class GeoBLEUMetric(Metric):\n",
        "    \"\"\"\n",
        "    M√©trica para calcular el puntaje GeoBLEU.\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate(self, predictions_per_user, validation_per_user):\n",
        "        return calculate_geobleu_for_quadrant(predictions_per_user, validation_per_user)\n",
        "\n",
        "\n",
        "class DTWMetric(Metric):\n",
        "    \"\"\"\n",
        "    M√©trica para calcular el puntaje de Dynamic Time Warping (DTW).\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate(self, predictions_per_user, validation_per_user):\n",
        "        return calculate_dtw_for_quadrant(predictions_per_user, validation_per_user)\n",
        "\n",
        "\n",
        "def calculate_lpp(predictions_per_user, validation_per_user, tolerance=4.0):\n",
        "    \"\"\"\n",
        "    Calcula la Precisi√≥n de Predicci√≥n de Ubicaci√≥n (LPP), ignorando los valores NaN,\n",
        "    y permitiendo un margen de error definido por un umbral.\n",
        "\n",
        "    Args:\n",
        "        predictions_per_user (list of list of tuples): Lista de trayectorias generadas por cada usuario.\n",
        "        validation_per_user (list of list of tuples): Lista de trayectorias reales por cada usuario.\n",
        "        tolerance (float): Margen de error en unidades de distancia para considerar una predicci√≥n correcta.\n",
        "\n",
        "    Returns:\n",
        "        float: La precisi√≥n de ubicaci√≥n como porcentaje de coincidencias dentro del margen.\n",
        "    \"\"\"\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for predicted_traj, actual_traj in zip(predictions_per_user, validation_per_user):\n",
        "        for predicted_point, actual_point in zip(predicted_traj, actual_traj):\n",
        "            # Asegurar que las coordenadas reales no sean NaN\n",
        "            if not any(np.isnan(coord) for coord in actual_point[2:]):\n",
        "                # Calcular distancia euclidiana entre puntos predichos y reales\n",
        "                distance = np.sqrt(\n",
        "                    (predicted_point[2] - actual_point[2]) ** 2\n",
        "                    + (predicted_point[3] - actual_point[3]) ** 2\n",
        "                )\n",
        "                # Contar como correcta si la distancia est√° dentro del margen de tolerancia\n",
        "                if distance <= tolerance:\n",
        "                    correct_predictions += 1\n",
        "                total_predictions += 1\n",
        "\n",
        "    # Calcular el porcentaje de precisi√≥n\n",
        "    lpp = (\n",
        "        (correct_predictions / total_predictions) * 100\n",
        "        if total_predictions > 0\n",
        "        else 0.0\n",
        "    )\n",
        "    return lpp\n",
        "\n",
        "\n",
        "def calculate_error_metrics(predictions_per_user, validation_per_user):\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas de error entre trayectorias predichas y reales:\n",
        "    - Error Medio Absoluto (MAE)\n",
        "    - Error M√°ximo\n",
        "    - Distribuci√≥n de Errores\n",
        "\n",
        "    Args:\n",
        "        predictions_per_user (list of list of tuples): Trayectorias predichas [(d, t, x, y)].\n",
        "        validation_per_user (list of list of tuples): Trayectorias reales [(d, t, x, y)].\n",
        "\n",
        "    Returns:\n",
        "        dict: M√©tricas calculadas.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "\n",
        "    for predicted_traj, actual_traj in zip(predictions_per_user, validation_per_user):\n",
        "        for predicted_point, actual_point in zip(predicted_traj, actual_traj):\n",
        "            # Ignorar puntos donde las coordenadas reales sean NaN\n",
        "            if not any(np.isnan(coord) for coord in actual_point[2:]):\n",
        "                # Calcular distancia euclidiana\n",
        "                distance = np.sqrt(\n",
        "                    (predicted_point[2] - actual_point[2]) ** 2\n",
        "                    + (predicted_point[3] - actual_point[3]) ** 2\n",
        "                )\n",
        "                errors.append(distance)\n",
        "\n",
        "    # Calcular m√©tricas\n",
        "    mae = np.mean(errors) if errors else 0.0\n",
        "    max_error = np.max(errors) if errors else 0.0\n",
        "\n",
        "    # Retornar resultados\n",
        "    return {\"MAE\": mae, \"Max Error\": max_error, \"Errors\": errors}\n",
        "\n",
        "\n",
        "def calculate_geobleu_for_quadrant(predictions_per_user, validation_per_user):\n",
        "    \"\"\"\n",
        "    Calcula el puntaje promedio de GeoBLEU para cada usuario comparando las trayectorias generadas y de referencia.\n",
        "\n",
        "    Args:\n",
        "        predictions_per_user (list of list of tuples): Lista de trayectorias generadas por cada usuario.\n",
        "        validation_per_user (list of list of tuples): Lista de trayectorias de referencia por cada usuario.\n",
        "\n",
        "    Returns:\n",
        "        float: El puntaje promedio de GeoBLEU para todos los usuarios comparados.\n",
        "    \"\"\"\n",
        "    total_score = 0\n",
        "    valid_users = 0\n",
        "    for predictions, validation in zip(predictions_per_user, validation_per_user):\n",
        "        if predictions and validation:  # Aseguramos que haya datos comparables\n",
        "            score = geobleu.calc_geobleu(predictions, validation, processes=3)\n",
        "            total_score += score\n",
        "            valid_users += 1\n",
        "    return total_score / valid_users if valid_users else 0\n",
        "\n",
        "\n",
        "def calculate_dtw_for_quadrant(predictions_per_user, validation_per_user):\n",
        "    \"\"\"\n",
        "    Calcula el puntaje promedio de DTW para cada usuario comparando las trayectorias generadas y de referencia.\n",
        "\n",
        "    Args:\n",
        "        predictions_per_user (list of list of tuples): Lista de trayectorias generadas por cada usuario.\n",
        "        validation_per_user (list of list of tuples): Lista de trayectorias de referencia por cada usuario.\n",
        "\n",
        "    Returns:\n",
        "        float: El puntaje promedio de DTW para todos los usuarios comparados.\n",
        "    \"\"\"\n",
        "    total_score = 0\n",
        "    valid_users = 0\n",
        "    for predictions, validation in zip(predictions_per_user, validation_per_user):\n",
        "        if predictions and validation:  # Aseguramos que haya datos comparables\n",
        "            score = geobleu.calc_dtw(predictions, validation)\n",
        "            total_score += score\n",
        "            valid_users += 1\n",
        "    return total_score / valid_users if valid_users else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imc5AgLcspzl",
        "outputId": "32aaeb02-0bde-4c21-a900-92fca5c1549e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de las M√©tricas:\n",
            "LPPMetric score: 32.35294117647059\n",
            "MAEMetric score: 31.702480626160508\n",
            "DTWMetric score: 72.92499549871108\n",
            "GeoBLEUMetric score: 0.05015959920904115\n"
          ]
        }
      ],
      "source": [
        "metrics_instances = [\n",
        "    LPPMetric(),\n",
        "    MAEMetric(),\n",
        "    DTWMetric(),\n",
        "    GeoBLEUMetric(),\n",
        "]\n",
        "# Calcular m√©tricas\n",
        "results = {}\n",
        "for metric in metrics_instances:\n",
        "    metric_name = type(metric).__name__\n",
        "    results[metric_name] = metric.calculate([generated_sequences], [reference_sequences])\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Resultados de las M√©tricas:\")\n",
        "for metric_name, score in results.items():\n",
        "    print(f\"{metric_name} score: {score}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
