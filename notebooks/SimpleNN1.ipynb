{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.mobility_data_manager import DataManager\n",
    "from utils.common import load_data, Data\n",
    "\n",
    "\n",
    "SELECTED_DATA= Data.FIRST_3000\n",
    "model_path=\"../Data/Models/Simple_NN.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(SELECTED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del DataFrame: (3642173, 5)\n",
      "\n",
      "Primeras filas del DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>d</th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   d   t   x   y\n",
       "0    0   0  25  75  82\n",
       "1    0   0  24  76  86\n",
       "2    0   0  22  81  89\n",
       "3    0  18  13  86  97\n",
       "4    0  18  12  85  97"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen estadístico:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>d</th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.642173e+06</td>\n",
       "      <td>3.642173e+06</td>\n",
       "      <td>3.642173e+06</td>\n",
       "      <td>3.642173e+06</td>\n",
       "      <td>3.642173e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.493830e+03</td>\n",
       "      <td>3.746488e+01</td>\n",
       "      <td>2.573454e+01</td>\n",
       "      <td>1.228730e+02</td>\n",
       "      <td>8.511531e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.666647e+02</td>\n",
       "      <td>2.168419e+01</td>\n",
       "      <td>1.142356e+01</td>\n",
       "      <td>4.246668e+01</td>\n",
       "      <td>4.273534e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.450000e+02</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>5.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.503000e+03</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>1.260000e+02</td>\n",
       "      <td>8.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.246000e+03</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>1.560000e+02</td>\n",
       "      <td>1.110000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.999000e+03</td>\n",
       "      <td>7.400000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.000000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uid             d             t             x             y\n",
       "count  3.642173e+06  3.642173e+06  3.642173e+06  3.642173e+06  3.642173e+06\n",
       "mean   1.493830e+03  3.746488e+01  2.573454e+01  1.228730e+02  8.511531e+01\n",
       "std    8.666647e+02  2.168419e+01  1.142356e+01  4.246668e+01  4.273534e+01\n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00\n",
       "25%    7.450000e+02  1.900000e+01  1.700000e+01  9.400000e+01  5.700000e+01\n",
       "50%    1.503000e+03  3.800000e+01  2.600000e+01  1.260000e+02  8.300000e+01\n",
       "75%    2.246000e+03  5.700000e+01  3.500000e+01  1.560000e+02  1.110000e+02\n",
       "max    2.999000e+03  7.400000e+01  4.700000e+01  2.000000e+02  2.000000e+02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Dimensiones del DataFrame: {df.shape}\")\n",
    "# print(\"\\nInformación del DataFrame:\")\n",
    "# display(df.info())\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nResumen estadístico:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configurar el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Divide los datos en entrenamiento, validación y prueba según el rango de días.\n",
    "    \"\"\"\n",
    "    train = df[df[\"d\"] < 44]  # Días antes de validación\n",
    "    val = df[\n",
    "        (df[\"d\"] >= 37) & (df[\"d\"] < 59)\n",
    "    ]  # Incluye días de entrada y target para validación\n",
    "    test = df[(df[\"d\"] >= 52)]  # Incluye días de entrada y target para prueba\n",
    "    return train.copy(), val.copy(), test.copy()\n",
    "\n",
    "\n",
    "def create_sequences(data, scaler, input_days=7, target_days=7, padding_value=-1):\n",
    "    \"\"\"\n",
    "    Genera secuencias de entrada basadas en los últimos 15 días para predecir los próximos 7 días.\n",
    "    Incluye uid, d, t, x, y en las secuencias.\n",
    "    \"\"\"\n",
    "    X, y, input_masks, target_masks = [], [], [], []\n",
    "    users = data[\"uid\"].unique()\n",
    "\n",
    "    for uid in users:\n",
    "        user_data = data[data[\"uid\"] == uid]\n",
    "        days = sorted(user_data[\"d\"].unique())  # Ordenar los días únicos\n",
    "\n",
    "        # Rellenar días faltantes\n",
    "        complete_data = []\n",
    "        for day in days:\n",
    "            day_data = user_data[user_data[\"d\"] == day]\n",
    "            if len(day_data) < 48:\n",
    "                # Crear DataFrame con todos los timeslots (completos con padding_value)\n",
    "                filled_day = pd.DataFrame(\n",
    "                    {\"t\": range(48), \"x\": padding_value, \"y\": padding_value}\n",
    "                ).astype(float)\n",
    "                filled_day = pd.merge(\n",
    "                    filled_day, day_data[[\"t\", \"x\", \"y\"]], on=\"t\", how=\"left\"\n",
    "                )\n",
    "                filled_day[\"x\"] = filled_day[\"x_y\"].fillna(filled_day[\"x_x\"])\n",
    "                filled_day[\"y\"] = filled_day[\"y_y\"].fillna(filled_day[\"y_x\"])\n",
    "                filled_day = filled_day[[\"t\", \"x\", \"y\"]]\n",
    "                filled_day[\"d\"] = day\n",
    "                filled_day[\"uid\"] = uid\n",
    "                filled_day = filled_day[[\"uid\", \"d\", \"t\", \"x\", \"y\"]]\n",
    "                complete_data.append(filled_day)\n",
    "            else:\n",
    "                day_data = day_data[[\"uid\", \"d\", \"t\", \"x\", \"y\"]]\n",
    "                complete_data.append(day_data)\n",
    "\n",
    "        complete_data = pd.concat(complete_data).reset_index(drop=True)\n",
    "\n",
    "        # Crear secuencias de 15 días para predecir 7 días\n",
    "        for i in range(len(days) - (input_days + target_days)):\n",
    "            input_seq_days = days[i : i + input_days]\n",
    "            target_seq_days = days[i + input_days : i + input_days + target_days]\n",
    "\n",
    "            # Seleccionar las secuencias de entrada y objetivo\n",
    "            input_seq = complete_data[complete_data[\"d\"].isin(input_seq_days)].copy()\n",
    "            target_seq = complete_data[complete_data[\"d\"].isin(target_seq_days)].copy()\n",
    "\n",
    "            # Crear máscaras para identificar valores válidos en x, y\n",
    "            mask_input_non_padding = (input_seq[[\"x\", \"y\"]] != padding_value).all(\n",
    "                axis=1\n",
    "            )\n",
    "            mask_target_non_padding = (target_seq[[\"x\", \"y\"]] != padding_value).all(\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            # Normalizar todas las columnas de d y t\n",
    "            input_seq[[\"d\", \"t\"]] = scaler.transform(input_seq[[\"d\", \"t\", \"x\", \"y\"]])[\n",
    "                :, :2\n",
    "            ]\n",
    "            target_seq[[\"d\", \"t\"]] = scaler.transform(target_seq[[\"d\", \"t\", \"x\", \"y\"]])[\n",
    "                :, :2\n",
    "            ]\n",
    "\n",
    "            # Normalizar x, y únicamente donde no sean -1\n",
    "            input_seq.loc[mask_input_non_padding, [\"x\", \"y\"]] = scaler.transform(\n",
    "                input_seq.loc[mask_input_non_padding, [\"d\", \"t\", \"x\", \"y\"]]\n",
    "            )[:, -2:]\n",
    "            target_seq.loc[mask_target_non_padding, [\"x\", \"y\"]] = scaler.transform(\n",
    "                target_seq.loc[mask_target_non_padding, [\"d\", \"t\", \"x\", \"y\"]]\n",
    "            )[:, -2:]\n",
    "\n",
    "            if (\n",
    "                len(input_seq) == input_days * 48\n",
    "                and len(target_seq) == target_days * 48\n",
    "            ):\n",
    "                # Incluir todas las características\n",
    "                X.append(input_seq[[\"uid\", \"d\", \"t\", \"x\", \"y\"]].values)\n",
    "                y.append(target_seq[[\"x\", \"y\"]].values)\n",
    "\n",
    "                # Crear máscaras para identificar valores válidos\n",
    "                input_mask = (input_seq[[\"x\", \"y\"]].values != padding_value).astype(int)\n",
    "                target_mask = (target_seq[[\"x\", \"y\"]].values != padding_value).astype(\n",
    "                    int\n",
    "                )\n",
    "                input_masks.append(input_mask)\n",
    "                target_masks.append(target_mask)\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    input_masks = np.array(input_masks, dtype=np.float32)\n",
    "    target_masks = np.array(target_masks, dtype=np.float32)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(X),\n",
    "        torch.tensor(y),\n",
    "        torch.tensor(input_masks),\n",
    "        torch.tensor(target_masks),\n",
    "    )\n",
    "\n",
    "\n",
    "def masked_loss_function(preds, targets, mask):\n",
    "    \"\"\"\n",
    "    Calcula la pérdida ignorando los valores con padding.\n",
    "    \"\"\"\n",
    "    # Ajustar dimensiones para que coincidan con targets\n",
    "    mask = mask.expand_as(targets)\n",
    "\n",
    "    # Aplicar la máscara a la pérdida\n",
    "    mse_loss = (preds - targets) ** 2\n",
    "    mse_loss = mse_loss[mask.bool()]  # Filtrar valores con la máscara\n",
    "    return mse_loss.mean()\n",
    "\n",
    "\n",
    "def fit_global_scaler(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Ajusta un `MinMaxScaler` global usando todos los datos disponibles.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Datos originales.\n",
    "\n",
    "    Returns:\n",
    "        MinMaxScaler: Escalador ajustado a todos los datos.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data[[\"d\", \"t\", \"x\", \"y\"]])  # Ajustar con las columnas relevantes\n",
    "    return scaler\n",
    "\n",
    "\n",
    "def normalize_data(data: pd.DataFrame, scaler: MinMaxScaler):\n",
    "    \"\"\"\n",
    "    Aplica un `scaler` existente a los datos para normalizarlos.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Datos a normalizar.\n",
    "        scaler (MinMaxScaler): Escalador ajustado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Datos normalizados.\n",
    "    \"\"\"\n",
    "    data[[\"d\", \"t\", \"x\", \"y\"]] = scaler.transform(data[[\"d\", \"t\", \"x\", \"y\"]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNNDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset para manejar secuencias con padding y máscaras.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, input_masks, target_masks):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.input_masks = input_masks\n",
    "        self.target_masks = target_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.input_masks[idx], self.target_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Red neuronal para predecir 7 días basados en los 15 días previos, utilizando todas las características.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size=5, hidden_size=128, output_size=2, num_layers=3, dropout=0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size: Dimensión de las features de entrada (e.g., uid, d, t, x, y).\n",
    "            hidden_size: Número de neuronas en las capas ocultas.\n",
    "            output_size: Dimensión de la salida (e.g., x, y predichos).\n",
    "            num_layers: Número de capas ocultas.\n",
    "            dropout: Probabilidad de dropout para evitar overfitting.\n",
    "        \"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(input_size, hidden_size))  # Capa oculta\n",
    "            layers.append(nn.ReLU())  # Activación\n",
    "            layers.append(nn.Dropout(dropout))  # Dropout\n",
    "            input_size = hidden_size  # La salida de la capa anterior es la entrada de la siguiente\n",
    "\n",
    "        layers.append(nn.Linear(hidden_size, output_size))  # Capa de salida\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor de entrada de dimensiones [batch_size, seq_len, input_size].\n",
    "        Returns:\n",
    "            Tensor de salida de dimensiones [batch_size, seq_len, output_size].\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_size = x.size()\n",
    "        \n",
    "        # Aplanar para procesar con capas lineales\n",
    "        x = x.view(batch_size * seq_len, input_size)\n",
    "\n",
    "        # Pasar a través de la red\n",
    "        x = self.network(x)\n",
    "\n",
    "        # Restaurar dimensiones originales\n",
    "        return x.view(batch_size, seq_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_scaler = fit_global_scaler(df)\n",
    "\n",
    "# Dividir los datos\n",
    "train_df, val_df, test_df = split_data(df)\n",
    "\n",
    "train_X, train_y, train_input_masks, train_target_masks = create_sequences(\n",
    "    train_df, global_scaler, input_days=7, target_days=7, padding_value=-1\n",
    ")\n",
    "val_X, val_y, val_input_masks, val_target_masks = create_sequences(\n",
    "    val_df, global_scaler, input_days=7, target_days=7, padding_value=-1\n",
    ")\n",
    "test_X, test_y, test_input_masks, test_target_masks = create_sequences(\n",
    "    test_df, global_scaler, input_days=7, target_days=7, padding_value=-1\n",
    ")\n",
    "\n",
    "# Crear datasets y dataloaders\n",
    "train_dataset = SimpleNNDataset(train_X, train_y, train_input_masks, train_target_masks)\n",
    "val_dataset = SimpleNNDataset(val_X, val_y, val_input_masks, val_target_masks)\n",
    "test_dataset = SimpleNNDataset(test_X, test_y, test_input_masks, test_target_masks)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs=20,\n",
    "    lr=0.001,\n",
    "):\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    best_epoch = -1\n",
    "    best_model_state = None\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X, y, input_mask, target_mask in train_loader:\n",
    "\n",
    "            X, y, input_mask, target_mask = (\n",
    "\n",
    "                X.to(device),\n",
    "\n",
    "                y.to(device),\n",
    "\n",
    "                input_mask.to(device),\n",
    "\n",
    "                target_mask.to(device),\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(X)\n",
    "\n",
    "            loss = masked_loss_function(preds, y, target_mask)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for X, y, input_mask, target_mask in val_loader:\n",
    "\n",
    "                X, y, input_mask, target_mask = (\n",
    "\n",
    "                    X.to(device),\n",
    "\n",
    "                    y.to(device),\n",
    "\n",
    "                    input_mask.to(device),\n",
    "\n",
    "                    target_mask.to(device),\n",
    "                )\n",
    "\n",
    "                preds = model(X)\n",
    "\n",
    "                loss = masked_loss_function(preds, y, target_mask)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "        # Verificar si esta es la mejor época\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, train_losses, val_losses, best_epoch\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Evalúa el modelo en un conjunto de datos utilizando masked_loss_function.\n",
    "\n",
    "    Retorna la pérdida promedio del conjunto de datos.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, (X, y, input_mask, target_mask) in enumerate(data_loader):\n",
    "\n",
    "            # Enviar datos al dispositivo\n",
    "\n",
    "            X, y, input_mask, target_mask = (\n",
    "\n",
    "                X.to(device),\n",
    "\n",
    "                y.to(device),\n",
    "\n",
    "                input_mask.to(device),\n",
    "\n",
    "                target_mask.to(device),\n",
    "            )\n",
    "\n",
    "\n",
    "            # Predicción del modelo\n",
    "\n",
    "            outputs = model(X)\n",
    "\n",
    "\n",
    "            # Calcular pérdida usando la máscara\n",
    "\n",
    "            loss = masked_loss_function(outputs, y, target_mask)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "    # Evitar división por cero en caso de un DataLoader vacío\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, val_losses, best_epoch):\n",
    "    \"\"\"\n",
    "\n",
    "    Grafica las pérdidas de entrenamiento y validación.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        train_losses,\n",
    "\n",
    "        label=\"Training Loss\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        val_losses,\n",
    "\n",
    "        label=\"Validation Loss\",\n",
    "    )\n",
    "\n",
    "    plt.axvline(\n",
    "\n",
    "        best_epoch - 1,\n",
    "\n",
    "        color=\"red\",\n",
    "\n",
    "        linestyle=\"--\",\n",
    "\n",
    "        label=f\"Best Model (Epoch {best_epoch})\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 51.5845, Val Loss: 0.0744\n",
      "Epoch [2/100], Train Loss: 0.0675, Val Loss: 0.0458\n",
      "Epoch [3/100], Train Loss: 0.0504, Val Loss: 0.0456\n",
      "Epoch [4/100], Train Loss: 0.0454, Val Loss: 0.0450\n",
      "Epoch [5/100], Train Loss: 0.0410, Val Loss: 0.0378\n",
      "Epoch [6/100], Train Loss: 0.0396, Val Loss: 0.0388\n",
      "Epoch [7/100], Train Loss: 0.0392, Val Loss: 0.0376\n",
      "Epoch [8/100], Train Loss: 0.0385, Val Loss: 0.0365\n",
      "Epoch [9/100], Train Loss: 0.0378, Val Loss: 0.0357\n",
      "Epoch [10/100], Train Loss: 0.0376, Val Loss: 0.0383\n",
      "Epoch [11/100], Train Loss: 0.0376, Val Loss: 0.0364\n",
      "Epoch [12/100], Train Loss: 0.0377, Val Loss: 0.0415\n",
      "Epoch [13/100], Train Loss: 0.0377, Val Loss: 0.0359\n",
      "Epoch [14/100], Train Loss: 0.0375, Val Loss: 0.0356\n",
      "Epoch [15/100], Train Loss: 0.0375, Val Loss: 0.0353\n",
      "Epoch [16/100], Train Loss: 0.0374, Val Loss: 0.0365\n",
      "Epoch [17/100], Train Loss: 0.0374, Val Loss: 0.0355\n",
      "Epoch [18/100], Train Loss: 0.0374, Val Loss: 0.0365\n",
      "Epoch [19/100], Train Loss: 0.0372, Val Loss: 0.0362\n",
      "Epoch [20/100], Train Loss: 0.0371, Val Loss: 0.0351\n",
      "Epoch [21/100], Train Loss: 0.0354, Val Loss: 0.0348\n",
      "Epoch [22/100], Train Loss: 0.0351, Val Loss: 0.0337\n",
      "Epoch [23/100], Train Loss: 0.0351, Val Loss: 0.0334\n",
      "Epoch [24/100], Train Loss: 0.0321, Val Loss: 0.0323\n",
      "Epoch [25/100], Train Loss: 0.0305, Val Loss: 0.0301\n",
      "Epoch [26/100], Train Loss: 0.0296, Val Loss: 0.0298\n",
      "Epoch [27/100], Train Loss: 0.0293, Val Loss: 0.0306\n",
      "Epoch [28/100], Train Loss: 0.0290, Val Loss: 0.0300\n",
      "Epoch [29/100], Train Loss: 0.0280, Val Loss: 0.0304\n",
      "Epoch [30/100], Train Loss: 0.0277, Val Loss: 0.0305\n",
      "Epoch [31/100], Train Loss: 0.0278, Val Loss: 0.0296\n",
      "Epoch [32/100], Train Loss: 0.0288, Val Loss: 0.0295\n",
      "Epoch [33/100], Train Loss: 0.0279, Val Loss: 0.0288\n",
      "Epoch [34/100], Train Loss: 0.0277, Val Loss: 0.0285\n",
      "Epoch [35/100], Train Loss: 0.0279, Val Loss: 0.0290\n",
      "Epoch [36/100], Train Loss: 0.0274, Val Loss: 0.0282\n",
      "Epoch [37/100], Train Loss: 0.0273, Val Loss: 0.0294\n",
      "Epoch [38/100], Train Loss: 0.0273, Val Loss: 0.0294\n",
      "Epoch [39/100], Train Loss: 0.0274, Val Loss: 0.0286\n",
      "Epoch [40/100], Train Loss: 0.0284, Val Loss: 0.0289\n",
      "Epoch [41/100], Train Loss: 0.0280, Val Loss: 0.0286\n",
      "Epoch [42/100], Train Loss: 0.0271, Val Loss: 0.0293\n",
      "Epoch [43/100], Train Loss: 0.0273, Val Loss: 0.0280\n",
      "Epoch [44/100], Train Loss: 0.0277, Val Loss: 0.0290\n",
      "Epoch [45/100], Train Loss: 0.0277, Val Loss: 0.0280\n",
      "Epoch [46/100], Train Loss: 0.0281, Val Loss: 0.0297\n",
      "Epoch [47/100], Train Loss: 0.0279, Val Loss: 0.0285\n",
      "Epoch [48/100], Train Loss: 0.0278, Val Loss: 0.0280\n",
      "Epoch [49/100], Train Loss: 0.0285, Val Loss: 0.0289\n",
      "Epoch [50/100], Train Loss: 0.0278, Val Loss: 0.0296\n",
      "Epoch [51/100], Train Loss: 0.0279, Val Loss: 0.0287\n",
      "Epoch [52/100], Train Loss: 0.0274, Val Loss: 0.0306\n",
      "Epoch [53/100], Train Loss: 0.0280, Val Loss: 0.0278\n",
      "Epoch [54/100], Train Loss: 0.0274, Val Loss: 0.0283\n",
      "Epoch [55/100], Train Loss: 0.0272, Val Loss: 0.0297\n",
      "Epoch [56/100], Train Loss: 0.0273, Val Loss: 0.0294\n",
      "Epoch [57/100], Train Loss: 0.0271, Val Loss: 0.0293\n",
      "Epoch [58/100], Train Loss: 0.0269, Val Loss: 0.0284\n",
      "Epoch [59/100], Train Loss: 0.0267, Val Loss: 0.0286\n",
      "Epoch [60/100], Train Loss: 0.0268, Val Loss: 0.0293\n",
      "Epoch [61/100], Train Loss: 0.0274, Val Loss: 0.0294\n",
      "Epoch [62/100], Train Loss: 0.0281, Val Loss: 0.0299\n",
      "Epoch [63/100], Train Loss: 0.0273, Val Loss: 0.0289\n",
      "Epoch [64/100], Train Loss: 0.0275, Val Loss: 0.0283\n",
      "Epoch [65/100], Train Loss: 0.0273, Val Loss: 0.0292\n",
      "Epoch [66/100], Train Loss: 0.0270, Val Loss: 0.0288\n",
      "Epoch [67/100], Train Loss: 0.0271, Val Loss: 0.0296\n",
      "Epoch [68/100], Train Loss: 0.0275, Val Loss: 0.0305\n",
      "Epoch [69/100], Train Loss: 0.0270, Val Loss: 0.0290\n",
      "Epoch [70/100], Train Loss: 0.0268, Val Loss: 0.0310\n",
      "Epoch [71/100], Train Loss: 0.0268, Val Loss: 0.0282\n",
      "Epoch [72/100], Train Loss: 0.0268, Val Loss: 0.0293\n",
      "Epoch [73/100], Train Loss: 0.0268, Val Loss: 0.0284\n",
      "Epoch [74/100], Train Loss: 0.0271, Val Loss: 0.0286\n",
      "Epoch [75/100], Train Loss: 0.0269, Val Loss: 0.0284\n",
      "Epoch [76/100], Train Loss: 0.0268, Val Loss: 0.0284\n",
      "Epoch [77/100], Train Loss: 0.0266, Val Loss: 0.0286\n",
      "Epoch [78/100], Train Loss: 0.0269, Val Loss: 0.0296\n",
      "Epoch [79/100], Train Loss: 0.0267, Val Loss: 0.0288\n",
      "Epoch [80/100], Train Loss: 0.0269, Val Loss: 0.0285\n",
      "Epoch [81/100], Train Loss: 0.0268, Val Loss: 0.0296\n",
      "Epoch [82/100], Train Loss: 0.0270, Val Loss: 0.0276\n",
      "Epoch [83/100], Train Loss: 0.0266, Val Loss: 0.0278\n",
      "Epoch [84/100], Train Loss: 0.0268, Val Loss: 0.0283\n",
      "Epoch [85/100], Train Loss: 0.0266, Val Loss: 0.0295\n",
      "Epoch [86/100], Train Loss: 0.0272, Val Loss: 0.0294\n",
      "Epoch [87/100], Train Loss: 0.0265, Val Loss: 0.0285\n",
      "Epoch [88/100], Train Loss: 0.0272, Val Loss: 0.0284\n",
      "Epoch [89/100], Train Loss: 0.0279, Val Loss: 0.0282\n",
      "Epoch [90/100], Train Loss: 0.0272, Val Loss: 0.0290\n",
      "Epoch [91/100], Train Loss: 0.0267, Val Loss: 0.0280\n",
      "Epoch [92/100], Train Loss: 0.0268, Val Loss: 0.0280\n",
      "Epoch [93/100], Train Loss: 0.0267, Val Loss: 0.0310\n",
      "Epoch [94/100], Train Loss: 0.0266, Val Loss: 0.0285\n",
      "Epoch [95/100], Train Loss: 0.0262, Val Loss: 0.0278\n",
      "Epoch [96/100], Train Loss: 0.0266, Val Loss: 0.0286\n",
      "Epoch [97/100], Train Loss: 0.0265, Val Loss: 0.0279\n",
      "Epoch [98/100], Train Loss: 0.0262, Val Loss: 0.0288\n",
      "Epoch [99/100], Train Loss: 0.0262, Val Loss: 0.0280\n",
      "Epoch [100/100], Train Loss: 0.0271, Val Loss: 0.0287\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "EPOCHS = 100\n",
    "model = SimpleNN(input_size=5, hidden_size=128, output_size=2, num_layers=3, dropout=0.2)\n",
    "\n",
    "\n",
    "# Entrenar y validar el modelo\n",
    "criterion = nn.MSELoss()\n",
    "model, train_losses, val_losses, best_epoch = train_and_validate_model(\n",
    "    model, train_loader, val_loader, epochs=EPOCHS, lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar las pérdidas\n",
    "plot_losses(train_losses, val_losses, best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0287\n",
      "Test Loss: 0.0281\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en el conjunto de validación\n",
    "val_loss = evaluate_model(model, val_loader)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "test_loss = evaluate_model(model, test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo completo guardado correctamente en 'simple_nn_complete.pth'.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"../Data/Models/Simple_NN.pth\")\n",
    "print(\"Modelo completo guardado correctamente en 'simple_nn_complete.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente desde 'simple_nn_complete.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian_iq\\AppData\\Local\\Temp\\ipykernel_36128\\2703897339.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo completo\n",
    "model = torch.load(model_path)\n",
    "model.eval()  # Configurar el modelo en modo evaluación\n",
    "\n",
    "print(\"Modelo cargado correctamente desde 'simple_nn_complete.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import Metric\n",
    "\n",
    "\n",
    "def generate_trajectories_with_masks(model, dataloader):\n",
    "    \"\"\"\n",
    "    Genera trayectorias estructuradas `(d, t, x, y)` utilizando las máscaras para\n",
    "    filtrar los valores válidos.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado.\n",
    "        dataloader (DataLoader): DataLoader con los datos normalizados.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Diccionarios con trayectorias predichas y reales estructuradas por usuario.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    predictions_per_user = {}\n",
    "    validation_per_user = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y, input_mask, target_mask in dataloader:\n",
    "            # Mover datos al dispositivo\n",
    "            X, y, target_mask = X.to(device), y.to(device), target_mask.to(device)\n",
    "\n",
    "            # Obtener predicciones del modelo\n",
    "            preds = model(X).cpu().numpy()  # [batch_size, 336, 2]\n",
    "            y = y.cpu().numpy()  # [batch_size, 336, 2]\n",
    "            target_mask = target_mask.cpu().numpy()  # [batch_size, 336, 2]\n",
    "\n",
    "            # Extraer información relevante de X\n",
    "            batch_size, seq_len, _ = X.shape\n",
    "            uids = X[:, :, 0].cpu().numpy().astype(int)  # UID del usuario\n",
    "            days = X[:, :, 1].cpu().numpy()  # Días\n",
    "            timeslots = X[:, :, 2].cpu().numpy()  # Timeslots\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                uid = uids[i, 0]  # El UID es constante en la secuencia\n",
    "                pred_traj = []\n",
    "                actual_traj = []\n",
    "\n",
    "                for j in range(seq_len):\n",
    "                    if target_mask[i, j, 0]:  # Verificar si el valor es válido\n",
    "                        pred_point = preds[i, j]\n",
    "                        target_point = y[i, j]\n",
    "\n",
    "                        pred_traj.append(\n",
    "                            (\n",
    "                                days[i, j],  # Día\n",
    "                                timeslots[i, j],  # Timeslot\n",
    "                                pred_point[0],  # Coordenada x\n",
    "                                pred_point[1],  # Coordenada y\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        actual_traj.append(\n",
    "                            (\n",
    "                                days[i, j],  # Día\n",
    "                                timeslots[i, j],  # Timeslot\n",
    "                                target_point[0],  # Coordenada x\n",
    "                                target_point[1],  # Coordenada y\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                if uid not in predictions_per_user:\n",
    "                    predictions_per_user[uid] = []\n",
    "                    validation_per_user[uid] = []\n",
    "\n",
    "                predictions_per_user[uid].append(pred_traj)\n",
    "                validation_per_user[uid].append(actual_traj)\n",
    "\n",
    "    return predictions_per_user, validation_per_user\n",
    "\n",
    "\n",
    "def evaluate_metrics_with_masks(\n",
    "    model,\n",
    "    dataloader,\n",
    "    metrics: list[Metric],\n",
    "    scaler,\n",
    "    feature_columns=[\"d\", \"t\", \"x\", \"y\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Evalúa métricas utilizando trayectorias estructuradas desde el DataLoader y máscaras.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado.\n",
    "        dataloader (DataLoader): DataLoader con los datos normalizados.\n",
    "        metrics (list[Metric]): Lista de métricas a calcular.\n",
    "        scaler (MinMaxScaler): Escalador utilizado para normalizar y revertir la normalización.\n",
    "        feature_columns (list): Columnas utilizadas para normalización/desnormalización.\n",
    "\n",
    "    Returns:\n",
    "        dict: Diccionario con los resultados de las métricas.\n",
    "    \"\"\"\n",
    "    # Generar trayectorias estructuradas con máscaras\n",
    "    predictions_per_user, validation_per_user = generate_trajectories_with_masks(\n",
    "        model, dataloader\n",
    "    )\n",
    "\n",
    "    # Desnormalizar y convertir a enteros las trayectorias\n",
    "    def denormalize_trajectories(trajectories, scaler):\n",
    "        denormalized = {}\n",
    "        for uid, traj_list in trajectories.items():\n",
    "            denormalized[uid] = []\n",
    "            for traj in traj_list:\n",
    "                denormalized_traj = []\n",
    "                for point in traj:\n",
    "                    d, t, x, y = point\n",
    "                    denormalized_point = scaler.inverse_transform([[d, t, x, y]])[0]\n",
    "                    denormalized_traj.append(\n",
    "                        (\n",
    "                            int(round(denormalized_point[0])),  # Día (entero)\n",
    "                            int(round(denormalized_point[1])),  # Timeslot (entero)\n",
    "                            int(round(denormalized_point[2])),  # Coordenada x (entero)\n",
    "                            int(round(denormalized_point[3])),  # Coordenada y (entero)\n",
    "                        )\n",
    "                    )\n",
    "                denormalized[uid].append(denormalized_traj)\n",
    "        return denormalized\n",
    "\n",
    "    # Desnormalizar predicciones y validaciones\n",
    "    predictions_per_user = denormalize_trajectories(predictions_per_user, scaler)\n",
    "    validation_per_user = denormalize_trajectories(validation_per_user, scaler)\n",
    "\n",
    "    # Calcular métricas\n",
    "    results = {metric.__class__.__name__: [] for metric in metrics}\n",
    "\n",
    "    # Iterar sobre todos los usuarios en las predicciones\n",
    "    for uid in predictions_per_user.keys():\n",
    "        if uid in validation_per_user:\n",
    "            # Extraer las secciones para este usuario\n",
    "            user_predictions = predictions_per_user[uid]\n",
    "            user_validation = validation_per_user[uid]\n",
    "\n",
    "            # Calcular las métricas para este usuario\n",
    "            for metric in metrics:\n",
    "                score = metric.calculate(user_predictions, user_validation)\n",
    "                results[metric.__class__.__name__].append(score)\n",
    "        else:\n",
    "            print(f\"Usuario {uid} no encontrado en las validaciones.\")\n",
    "\n",
    "    # Calcular el promedio de las métricas para todos los usuarios\n",
    "    average_results = {\n",
    "        metric_name: np.mean(scores) if scores else 0.0\n",
    "        for metric_name, scores in results.items()\n",
    "    }\n",
    "\n",
    "    # Mostrar resultados\n",
    "    for metric_name, avg_score in average_results.items():\n",
    "        print(f\"{metric_name}: {avg_score:.4f}\")\n",
    "\n",
    "\n",
    "    # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPPMetric: 1.4121\n",
      "MAEMetric: 39.1371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LPPMetric': [0.5555555555555556,\n",
       "  0.17035775127768313,\n",
       "  3.8857142857142852,\n",
       "  3.909774436090226,\n",
       "  4.462895692786715,\n",
       "  0.17953321364452424,\n",
       "  1.5010351966873705,\n",
       "  18.8626907073509,\n",
       "  0.12239902080783352,\n",
       "  6.451612903225806,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1941747572815534,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6374501992031872,\n",
       "  2.8877887788778875,\n",
       "  1.5457788347205708,\n",
       "  9.949832775919733,\n",
       "  0.8939213349225268,\n",
       "  0.0,\n",
       "  0.29904306220095694,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7547169811320755,\n",
       "  0.0,\n",
       "  1.3398294762484775,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.521555367709214,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.381692573402418,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.370860927152318,\n",
       "  0.0,\n",
       "  0.4531722054380665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.087941976427924,\n",
       "  1.9178082191780823,\n",
       "  0.2849002849002849,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.4084507042253522,\n",
       "  0.0,\n",
       "  0.2079002079002079,\n",
       "  3.2994923857868024,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12.627291242362526,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4464285714285714,\n",
       "  0.0,\n",
       "  1.147227533460803,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.37907505686125853,\n",
       "  0.591715976331361,\n",
       "  0.7724301841948901,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.3032629558541267,\n",
       "  0.0,\n",
       "  3.0303030303030303,\n",
       "  0.0,\n",
       "  0.9102730819245773,\n",
       "  0.411764705882353,\n",
       "  0.4434589800443459,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.4173228346456692,\n",
       "  0.0,\n",
       "  45.057766367137354,\n",
       "  0.0,\n",
       "  0.6818181818181818,\n",
       "  2.1834061135371177,\n",
       "  0.3836317135549872,\n",
       "  0.0,\n",
       "  1.1121856866537718,\n",
       "  0.0,\n",
       "  48.63661658319421,\n",
       "  0.16556291390728478,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.15278838808250572,\n",
       "  0.0,\n",
       "  2.7777777777777777,\n",
       "  0.0,\n",
       "  11.147116007777058,\n",
       "  0.0,\n",
       "  29.37853107344633,\n",
       "  2.102496714848883,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.929368029739777,\n",
       "  0.0,\n",
       "  0.7911392405063291,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  26.692708333333332,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  15.568022440392706,\n",
       "  1.1784511784511784,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8036739380022963,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6711409395973155,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.273972602739726,\n",
       "  0.08278145695364239,\n",
       "  0.9375,\n",
       "  9.714285714285714,\n",
       "  2.2701475595913734,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9691780821917808,\n",
       "  0.6481481481481481,\n",
       "  0.37907505686125853,\n",
       "  0.0,\n",
       "  3.7257824143070044,\n",
       "  1.4912280701754386,\n",
       "  2.3255813953488373,\n",
       "  2.6622296173044924,\n",
       "  0.0,\n",
       "  1.634472511144131,\n",
       "  8.176100628930817,\n",
       "  0.0,\n",
       "  0.4143646408839779,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.0837004405286343,\n",
       "  1.002865329512894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4807692307692308,\n",
       "  7.712082262210797,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.1990407673860912,\n",
       "  17.41988496302383,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.1226944667201284,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  37.29372937293729,\n",
       "  0.0,\n",
       "  1.3641133263378804,\n",
       "  0.0,\n",
       "  0.8160237388724036,\n",
       "  1.2944983818770228,\n",
       "  9.700176366843033,\n",
       "  0.5313496280552604,\n",
       "  2.8309104820198927,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.006211180124224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.56657223796034,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.2443181818181825,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  14.416666666666666,\n",
       "  0.0,\n",
       "  0.6527415143603132,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.423236514522822,\n",
       "  2.601156069364162,\n",
       "  2.208588957055215,\n",
       "  1.1278195488721803,\n",
       "  1.2345679012345678,\n",
       "  0.2523128679562658,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.539448364336113,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  14.572864321608039,\n",
       "  62.526584432156525,\n",
       "  1.1157601115760112,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.7893864013267,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16666666666666669,\n",
       "  0.0,\n",
       "  1.59798149705635,\n",
       "  1.738334858188472,\n",
       "  7.783018867924528,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.8999999999999995,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.24906600249066002,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8314855875831485,\n",
       "  0.0,\n",
       "  0.0755287009063444,\n",
       "  0.0,\n",
       "  3.942652329749104,\n",
       "  0.0,\n",
       "  0.4072134962187318,\n",
       "  0.713436385255648,\n",
       "  0.2967359050445104,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.46367851622874806,\n",
       "  1.5174506828528074,\n",
       "  0.0,\n",
       "  1.4447884416924663,\n",
       "  2.6858213616489697,\n",
       "  0.5133470225872689,\n",
       "  0.0,\n",
       "  0.15232292460015232,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.19627085377821393,\n",
       "  0.0,\n",
       "  0.3468208092485549,\n",
       "  1.177730192719486,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5972696245733788,\n",
       "  8.02919708029197,\n",
       "  0.41109969167523125,\n",
       "  0.0,\n",
       "  0.9269356597600873,\n",
       "  1.1504424778761062,\n",
       "  1.2791572610985704,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6048387096774194,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.6861219195849546,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7961783439490446,\n",
       "  0.6144393241167435,\n",
       "  15.049864007252948,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.272727272727273,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4919184820801124,\n",
       "  0.4531722054380665,\n",
       "  12.687813021702837,\n",
       "  0.7782101167315175,\n",
       "  0.3393665158371041,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9146341463414633,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.48661800486618007,\n",
       "  0.0,\n",
       "  26.4026402640264,\n",
       "  32.41308793456032,\n",
       "  0.1724137931034483,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.5161744022503516,\n",
       "  1.1686143572621035,\n",
       "  0.0,\n",
       "  0.859106529209622,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9485094850948509,\n",
       "  0.9027777777777777,\n",
       "  0.8818342151675485,\n",
       "  0.0,\n",
       "  26.78751258811682,\n",
       "  0.0,\n",
       "  0.5959475566150179,\n",
       "  0.8733624454148471,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.138353765323993,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.21074815595363539,\n",
       "  1.6210739614994936,\n",
       "  1.0688836104513064,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.1376564277588168,\n",
       "  3.205629397967162,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.803921568627452,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.3679417122040074,\n",
       "  7.59027266028003,\n",
       "  2.393038433647571,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.844475721323012,\n",
       "  0.0,\n",
       "  0.7889546351084813,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  14.425427872860636,\n",
       "  0.0,\n",
       "  7.7799801783944496,\n",
       "  0.0,\n",
       "  0.41644976574700676,\n",
       "  0.2364066193853428,\n",
       "  0.0,\n",
       "  6.384364820846905,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0160880609652836,\n",
       "  2.9670329670329667,\n",
       "  0.0,\n",
       "  30.916334661354583,\n",
       "  0.4008016032064128,\n",
       "  1.5856236786469344,\n",
       "  0.0,\n",
       "  6.7669172932330826,\n",
       "  0.0,\n",
       "  11.103495544893763,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5649717514124294,\n",
       "  0.0,\n",
       "  2.338129496402878,\n",
       "  4.560475875743556,\n",
       "  14.052287581699346,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.309692671394799,\n",
       "  1.174496644295302,\n",
       "  30.178173719376396,\n",
       "  0.0,\n",
       "  0.5873715124816447,\n",
       "  0.7402837754472548,\n",
       "  17.07462686567164,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.178928247048138,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0935601458080195,\n",
       "  0.9749303621169917,\n",
       "  0.0,\n",
       "  11.72161172161172,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5891016200294551,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0672358591248665,\n",
       "  1.030337721808815,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6906077348066298,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12.482468443197755,\n",
       "  6.150341685649203,\n",
       "  0.9157509157509158,\n",
       "  0.0,\n",
       "  2.3032629558541267,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.186840471756673,\n",
       "  3.0162412993039442,\n",
       "  12.362030905077264,\n",
       "  0.0,\n",
       "  1.1904761904761905,\n",
       "  1.6069221260815822,\n",
       "  0.0,\n",
       "  0.15479876160990713,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.26666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22156573116691286,\n",
       "  0.0,\n",
       "  1.1947431302270013,\n",
       "  0.0,\n",
       "  0.27932960893854747,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.013422818791946,\n",
       "  0.0,\n",
       "  0.945945945945946,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9174311926605505,\n",
       "  0.0,\n",
       "  0.24189646831156267,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.036876355748373,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9198664440734556,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.930585683297181,\n",
       "  2.4539877300613497,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.25252525252525254,\n",
       "  0.0,\n",
       "  0.10438413361169101,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.2448979591836733,\n",
       "  0.0,\n",
       "  2.786377708978328,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.21253985122210414,\n",
       "  0.0,\n",
       "  2.846299810246679,\n",
       "  0.0,\n",
       "  0.16611295681063123,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22710068130204392,\n",
       "  6.90172543135784,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.27272727272727276,\n",
       "  11.705426356589149,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4136504653567736,\n",
       "  1.3824884792626728,\n",
       "  0.641025641025641,\n",
       "  4.285714285714286,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9107468123861567,\n",
       "  0.18761726078799248,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8849557522123894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.741654571843251,\n",
       "  1.0144927536231882,\n",
       "  7.960199004975125,\n",
       "  1.4795474325500435,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.8971119133574,\n",
       "  0.0,\n",
       "  18.6307519640853,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6747638326585695,\n",
       "  0.0,\n",
       "  31.43976493633692,\n",
       "  0.5037783375314862,\n",
       "  1.461038961038961,\n",
       "  0.0,\n",
       "  12.01923076923077,\n",
       "  0.0,\n",
       "  3.356890459363958,\n",
       "  0.0,\n",
       "  1.1494252873563218,\n",
       "  0.0,\n",
       "  1.9450800915331807,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.356846473029045,\n",
       "  0.503235082674335,\n",
       "  0.8264462809917356,\n",
       "  0.0,\n",
       "  0.936768149882904,\n",
       "  1.452513966480447,\n",
       "  0.0,\n",
       "  0.8793969849246231,\n",
       "  0.0,\n",
       "  4.258943781942079,\n",
       "  0.0,\n",
       "  0.8298755186721992,\n",
       "  0.3250975292587776,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  31.456043956043956,\n",
       "  0.0,\n",
       "  2.047082906857728,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.8683181225554106,\n",
       "  0.18703241895261846,\n",
       "  0.21505376344086022,\n",
       "  0.0,\n",
       "  0.6747638326585695,\n",
       "  5.0233644859813085,\n",
       "  16.60130718954248,\n",
       "  1.7610062893081762,\n",
       "  0.5060728744939271,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9250693802035153,\n",
       "  0.7396449704142012,\n",
       "  0.0,\n",
       "  0.20273694880892043,\n",
       "  0.32858707557502737,\n",
       "  0.0,\n",
       "  0.5090909090909091,\n",
       "  1.4690451206715633,\n",
       "  16.577540106951872,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.779510022271715,\n",
       "  0.0,\n",
       "  1.4227642276422763,\n",
       "  0.0,\n",
       "  0.5370569280343717,\n",
       "  0.2808988764044944,\n",
       "  0.0,\n",
       "  0.273972602739726,\n",
       "  1.7500000000000002,\n",
       "  10.382165605095542,\n",
       "  0.0,\n",
       "  40.57437407952872,\n",
       "  0.4716981132075472,\n",
       "  0.0,\n",
       "  0.7234726688102894,\n",
       "  0.0,\n",
       "  1.06951871657754,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22935779816513763,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  29.67525195968645,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9900990099009901,\n",
       "  0.0,\n",
       "  0.4576659038901602,\n",
       "  1.3850415512465373,\n",
       "  0.0,\n",
       "  0.8393285371702638,\n",
       "  0.48030739673390976,\n",
       "  0.0,\n",
       "  5.911552346570397,\n",
       "  0.3409090909090909,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5208333333333333,\n",
       "  0.8460236886632826,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.557377049180328,\n",
       "  10.022438294689604,\n",
       "  0.27347310847766637,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7009345794392523,\n",
       "  0.0,\n",
       "  4.582651391162029,\n",
       "  0.0,\n",
       "  1.4312977099236641,\n",
       "  0.0,\n",
       "  3.2148900169204735,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.36429872495446264,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.193992490613267,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5145797598627788,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.2996941896024465,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.32573289902280134,\n",
       "  2.5757575757575757,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20242914979757085,\n",
       "  0.0,\n",
       "  0.6578947368421052,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.35046728971962615,\n",
       "  24.43243243243243,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.42523033309709424,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.293470286133529,\n",
       "  0.9900990099009901,\n",
       "  1.3643659711075442,\n",
       "  0.3125,\n",
       "  0.0,\n",
       "  0.8383233532934131,\n",
       "  0.825082508250825,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.42662116040955633,\n",
       "  0.0,\n",
       "  0.6298110566829951,\n",
       "  30.57384760112888,\n",
       "  0.0,\n",
       "  28.687572590011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.6578073089700998,\n",
       "  0.0,\n",
       "  0.2881844380403458,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  15.111695137976348,\n",
       "  0.0,\n",
       "  0.05102040816326531,\n",
       "  7.291666666666667,\n",
       "  0.0,\n",
       "  6.332138590203106,\n",
       "  0.0,\n",
       "  4.354587869362364,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.6150740242261103,\n",
       "  2.066929133858268,\n",
       "  3.3946251768033946,\n",
       "  0.5031446540880503,\n",
       "  0.0,\n",
       "  1.0279001468428781,\n",
       "  0.33222591362126247,\n",
       "  1.1560693641618496,\n",
       "  0.2352941176470588,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8568980291345331,\n",
       "  0.0,\n",
       "  2.788844621513944,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.135135135135135,\n",
       "  41.2639405204461,\n",
       "  1.7699115044247788,\n",
       "  10.840534171249018,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  18.68020304568528,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.36986301369863,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1669449081803005,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.88622754491018,\n",
       "  0.0,\n",
       "  1.5366430260047281,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.4683153013910355,\n",
       "  0.0,\n",
       "  2.018633540372671,\n",
       "  0.7667031763417306,\n",
       "  0.0,\n",
       "  0.1762114537444934,\n",
       "  0.0,\n",
       "  0.7485029940119761,\n",
       "  28.019323671497588,\n",
       "  28.26797385620915,\n",
       "  0.0,\n",
       "  19.761499148211243,\n",
       "  0.0,\n",
       "  1.3626834381551363,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0719754977029097,\n",
       "  3.5746201966041107,\n",
       "  0.0,\n",
       "  0.9345794392523363,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0606060606060608,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.3563501849568433,\n",
       "  0.0,\n",
       "  0.8826583592938734,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  15.721231766612643,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20920502092050208,\n",
       "  0.19704433497536944,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.5691868758915835,\n",
       "  0.7772020725388601,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5502063273727648,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  43.5792349726776,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1443001443001443,\n",
       "  4.802744425385934,\n",
       "  2.4666397088556407,\n",
       "  0.0,\n",
       "  2.2058823529411766,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.213270142180095,\n",
       "  7.547169811320755,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0968921389396709,\n",
       "  0.7423117709437964,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.7389984825493165,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.921985815602838,\n",
       "  7.52157829839704,\n",
       "  5.161290322580645,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.3833110218652387,\n",
       "  0.0,\n",
       "  0.6445672191528545,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22935779816513763,\n",
       "  39.44603629417383,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.8292682926829267,\n",
       "  0.0,\n",
       "  3.2377428307123033,\n",
       "  1.0403120936280885,\n",
       "  0.0,\n",
       "  1.0816125860373649,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.45941807044410415,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0945179584120983,\n",
       "  6.956521739130435,\n",
       "  0.7283321194464676,\n",
       "  0.0,\n",
       "  1.38217000691085,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.46728971962616817,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.009345794392523,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.228039041703639,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.15544041450777202,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  19.69111969111969,\n",
       "  0.23094688221709006,\n",
       "  2.6415094339622645,\n",
       "  0.0,\n",
       "  0.9615384615384616,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10316368638239339,\n",
       "  0.10438413361169101,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.15633423180593,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.808290155440414,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  43.090211132437624,\n",
       "  0.823045267489712,\n",
       "  0.0,\n",
       "  1.6635859519408502,\n",
       "  0.4784688995215311,\n",
       "  0.0,\n",
       "  0.6586169045005488,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.257328990228013,\n",
       "  0.0,\n",
       "  0.6815968841285297,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.717472118959108,\n",
       "  0.7117437722419928,\n",
       "  1.1811023622047243,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20920502092050208,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09727626459143969,\n",
       "  26.726726726726728,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  24.404761904761905,\n",
       "  ...],\n",
       " 'MAEMetric': [np.float64(21.011886558136766),\n",
       "  np.float64(23.843613941833617),\n",
       "  np.float64(26.85809835319138),\n",
       "  np.float64(17.551153836733448),\n",
       "  np.float64(18.1218757377942),\n",
       "  np.float64(27.223928901277965),\n",
       "  np.float64(20.951852190652872),\n",
       "  np.float64(16.088176274196023),\n",
       "  np.float64(22.131742399278853),\n",
       "  np.float64(39.38636588387599),\n",
       "  np.float64(57.13038477979624),\n",
       "  np.float64(44.451383881164226),\n",
       "  np.float64(25.516808684554764),\n",
       "  np.float64(52.716239951722564),\n",
       "  np.float64(48.86889938942069),\n",
       "  np.float64(20.91899199812996),\n",
       "  np.float64(35.32847702981167),\n",
       "  np.float64(17.577466464898812),\n",
       "  np.float64(22.221910771643813),\n",
       "  np.float64(33.65439621934851),\n",
       "  np.float64(38.90634977402588),\n",
       "  np.float64(22.818314120133838),\n",
       "  np.float64(30.17330731353346),\n",
       "  np.float64(66.66481610587252),\n",
       "  np.float64(54.667611274021624),\n",
       "  np.float64(22.9562082738046),\n",
       "  np.float64(47.52105052942756),\n",
       "  np.float64(27.394321589739935),\n",
       "  np.float64(56.06639035598869),\n",
       "  np.float64(48.39088411514038),\n",
       "  np.float64(33.20864516580211),\n",
       "  np.float64(39.39320647233824),\n",
       "  np.float64(25.586026182489437),\n",
       "  np.float64(33.55283018097183),\n",
       "  np.float64(31.846313167325768),\n",
       "  np.float64(31.670845088748102),\n",
       "  np.float64(21.587277275710242),\n",
       "  np.float64(64.20428389749425),\n",
       "  np.float64(23.615048223327587),\n",
       "  np.float64(52.01165420200207),\n",
       "  np.float64(26.421843356440533),\n",
       "  np.float64(41.096624727150825),\n",
       "  np.float64(50.22633786165934),\n",
       "  np.float64(17.811637103364863),\n",
       "  np.float64(61.71162308833704),\n",
       "  np.float64(24.992136184319573),\n",
       "  np.float64(36.96432046183146),\n",
       "  np.float64(34.6641999301841),\n",
       "  np.float64(25.81799466630557),\n",
       "  np.float64(32.56775543818627),\n",
       "  np.float64(32.950381651092414),\n",
       "  np.float64(24.584879573757703),\n",
       "  np.float64(41.493134932610076),\n",
       "  np.float64(29.64357915793078),\n",
       "  np.float64(52.442829240483675),\n",
       "  np.float64(28.026783276367762),\n",
       "  np.float64(11.568251132122144),\n",
       "  np.float64(44.868666327906574),\n",
       "  np.float64(25.99581199578214),\n",
       "  np.float64(38.52137442293903),\n",
       "  np.float64(21.53116471446706),\n",
       "  np.float64(49.811584710028974),\n",
       "  np.float64(82.02076200471782),\n",
       "  np.float64(24.181071873855203),\n",
       "  np.float64(38.30822676203874),\n",
       "  np.float64(25.054987773222546),\n",
       "  np.float64(39.718819273913816),\n",
       "  np.float64(7.8141976267907625),\n",
       "  np.float64(35.20277880056972),\n",
       "  np.float64(31.812751341427834),\n",
       "  np.float64(32.01566762148408),\n",
       "  np.float64(70.18955615139446),\n",
       "  np.float64(43.10737845819593),\n",
       "  np.float64(39.038600516386374),\n",
       "  np.float64(35.47480072271756),\n",
       "  np.float64(42.14066820386596),\n",
       "  np.float64(37.675440935703435),\n",
       "  np.float64(30.124180481153438),\n",
       "  np.float64(57.780626248693245),\n",
       "  np.float64(38.07651003467308),\n",
       "  np.float64(24.451372213023262),\n",
       "  np.float64(65.68720642056873),\n",
       "  np.float64(30.37733053195473),\n",
       "  np.float64(39.696274620099395),\n",
       "  np.float64(43.47908021120652),\n",
       "  np.float64(50.02809675247579),\n",
       "  np.float64(53.59501091131696),\n",
       "  np.float64(15.275226106287205),\n",
       "  np.float64(46.9357779138815),\n",
       "  np.float64(15.758437073972997),\n",
       "  np.float64(23.325493080782522),\n",
       "  np.float64(36.362366130586395),\n",
       "  np.float64(63.28643509466202),\n",
       "  np.float64(43.429800182605625),\n",
       "  np.float64(21.03743795697004),\n",
       "  np.float64(41.635514390647536),\n",
       "  np.float64(8.829301434409913),\n",
       "  np.float64(32.08468593536895),\n",
       "  np.float64(17.901410100288903),\n",
       "  np.float64(14.265626847118252),\n",
       "  np.float64(32.127467863618904),\n",
       "  np.float64(41.304880110181415),\n",
       "  np.float64(23.238015616839483),\n",
       "  np.float64(46.189148412223425),\n",
       "  np.float64(50.10740985493665),\n",
       "  np.float64(21.737544387580556),\n",
       "  np.float64(84.53535085147108),\n",
       "  np.float64(48.45869057333034),\n",
       "  np.float64(29.907297509878187),\n",
       "  np.float64(39.38185113436189),\n",
       "  np.float64(44.65743363349827),\n",
       "  np.float64(28.598847039965243),\n",
       "  np.float64(27.43562459470105),\n",
       "  np.float64(15.10529450925838),\n",
       "  np.float64(28.56156552947553),\n",
       "  np.float64(37.88013788245077),\n",
       "  np.float64(27.843030469647164),\n",
       "  np.float64(74.62767250555896),\n",
       "  np.float64(42.001488972241106),\n",
       "  np.float64(85.30597616058007),\n",
       "  np.float64(25.892291301331696),\n",
       "  np.float64(20.67867964954086),\n",
       "  np.float64(29.533173045132592),\n",
       "  np.float64(31.293009886062038),\n",
       "  np.float64(32.808331281565316),\n",
       "  np.float64(15.645908577397956),\n",
       "  np.float64(15.529557442580705),\n",
       "  np.float64(41.126485401766935),\n",
       "  np.float64(65.0717873989271),\n",
       "  np.float64(53.99463909546021),\n",
       "  np.float64(25.053551148901555),\n",
       "  np.float64(66.85119819834874),\n",
       "  np.float64(39.44695134242459),\n",
       "  np.float64(26.21802290753362),\n",
       "  np.float64(50.31862348832873),\n",
       "  np.float64(51.20311521508947),\n",
       "  np.float64(48.379858466021076),\n",
       "  np.float64(55.19108804566778),\n",
       "  np.float64(42.49752650091222),\n",
       "  np.float64(52.3762787539665),\n",
       "  np.float64(99.76633185847858),\n",
       "  np.float64(83.73124888404867),\n",
       "  np.float64(31.970458104298437),\n",
       "  np.float64(32.215616503604764),\n",
       "  np.float64(36.04417146676981),\n",
       "  np.float64(26.087281898629907),\n",
       "  np.float64(51.83616526664722),\n",
       "  np.float64(66.33185555863041),\n",
       "  np.float64(34.455789158144974),\n",
       "  np.float64(39.50189263839687),\n",
       "  np.float64(39.827663564310704),\n",
       "  np.float64(15.494260298840949),\n",
       "  np.float64(54.3873012181596),\n",
       "  np.float64(27.71407786257723),\n",
       "  np.float64(55.32844208524463),\n",
       "  np.float64(29.05423570681954),\n",
       "  np.float64(31.037669983333004),\n",
       "  np.float64(31.819168358216384),\n",
       "  np.float64(62.30094550620772),\n",
       "  np.float64(33.16204808489093),\n",
       "  np.float64(80.70158146606197),\n",
       "  np.float64(31.18914588022602),\n",
       "  np.float64(37.66935618292165),\n",
       "  np.float64(21.857307694614875),\n",
       "  np.float64(51.479840834773235),\n",
       "  np.float64(93.9802956697399),\n",
       "  np.float64(21.157179791750288),\n",
       "  np.float64(19.305882045769582),\n",
       "  np.float64(59.26389479048946),\n",
       "  np.float64(41.96426093853545),\n",
       "  np.float64(32.43981236222263),\n",
       "  np.float64(15.78014940955414),\n",
       "  np.float64(57.50215924875537),\n",
       "  np.float64(23.00973389837903),\n",
       "  np.float64(14.915966698517908),\n",
       "  np.float64(41.96472463747817),\n",
       "  np.float64(35.497336707428744),\n",
       "  np.float64(40.438481950505995),\n",
       "  np.float64(34.08567379162375),\n",
       "  np.float64(56.96109018015155),\n",
       "  np.float64(23.28846004721024),\n",
       "  np.float64(31.062556405870147),\n",
       "  np.float64(16.59945734502945),\n",
       "  np.float64(39.350224246421426),\n",
       "  np.float64(18.975525466968733),\n",
       "  np.float64(39.4998137592684),\n",
       "  np.float64(46.17830786015692),\n",
       "  np.float64(31.03030128096824),\n",
       "  np.float64(7.5056462310548575),\n",
       "  np.float64(15.0729000730686),\n",
       "  np.float64(26.684603793478587),\n",
       "  np.float64(91.98994201738904),\n",
       "  np.float64(30.001152857872786),\n",
       "  np.float64(20.807586558612194),\n",
       "  np.float64(79.37744608365851),\n",
       "  np.float64(53.687903571409485),\n",
       "  np.float64(29.965301276710722),\n",
       "  np.float64(52.2179841325747),\n",
       "  np.float64(98.15070694325674),\n",
       "  np.float64(32.90219970833028),\n",
       "  np.float64(42.39697232526191),\n",
       "  np.float64(60.13875732242017),\n",
       "  np.float64(16.490272605010926),\n",
       "  np.float64(35.609222700270664),\n",
       "  np.float64(16.808742503967803),\n",
       "  np.float64(88.98406130313124),\n",
       "  np.float64(38.867368736338264),\n",
       "  np.float64(19.942025213701303),\n",
       "  np.float64(19.17467540219881),\n",
       "  np.float64(37.86728015102983),\n",
       "  np.float64(18.13555439177084),\n",
       "  np.float64(59.72992295759507),\n",
       "  np.float64(32.04859489751859),\n",
       "  np.float64(23.45461344998203),\n",
       "  np.float64(32.26563679634351),\n",
       "  np.float64(56.51356998890266),\n",
       "  np.float64(16.28623651916039),\n",
       "  np.float64(29.992830938158086),\n",
       "  np.float64(46.53077457412484),\n",
       "  np.float64(58.42702916654921),\n",
       "  np.float64(26.914671879609113),\n",
       "  np.float64(46.34895102243642),\n",
       "  np.float64(35.48663752657317),\n",
       "  np.float64(23.09279282854307),\n",
       "  np.float64(24.756402557123867),\n",
       "  np.float64(46.14152546871756),\n",
       "  np.float64(27.518389286882403),\n",
       "  np.float64(34.635071171036294),\n",
       "  np.float64(59.443321261851516),\n",
       "  np.float64(38.830237999078776),\n",
       "  np.float64(19.911325050285974),\n",
       "  np.float64(45.5290813955488),\n",
       "  np.float64(31.93161543548645),\n",
       "  np.float64(22.181777693554157),\n",
       "  np.float64(68.42404658234148),\n",
       "  np.float64(10.502678895862248),\n",
       "  np.float64(50.85521775792992),\n",
       "  np.float64(50.57319304608157),\n",
       "  np.float64(45.32818397051177),\n",
       "  np.float64(35.82582651884652),\n",
       "  np.float64(28.283287276523275),\n",
       "  np.float64(17.864214740644304),\n",
       "  np.float64(10.907582030636997),\n",
       "  np.float64(44.27386829479772),\n",
       "  np.float64(55.72034407922417),\n",
       "  np.float64(70.30251459376024),\n",
       "  np.float64(61.861559217418765),\n",
       "  np.float64(28.70378889099365),\n",
       "  np.float64(25.588470187520723),\n",
       "  np.float64(41.26415306471946),\n",
       "  np.float64(48.80806639509877),\n",
       "  np.float64(38.56221029415784),\n",
       "  np.float64(25.822980812488623),\n",
       "  np.float64(27.242545661175974),\n",
       "  np.float64(31.863896021720258),\n",
       "  np.float64(30.813308354749353),\n",
       "  np.float64(20.981996721933534),\n",
       "  np.float64(22.71681716158027),\n",
       "  np.float64(30.803337850834986),\n",
       "  np.float64(26.65874259025839),\n",
       "  np.float64(22.837374150973716),\n",
       "  np.float64(52.9254533598806),\n",
       "  np.float64(43.067050361069825),\n",
       "  np.float64(34.03623387310116),\n",
       "  np.float64(58.58758146556698),\n",
       "  np.float64(26.58341152736977),\n",
       "  np.float64(28.599462089460392),\n",
       "  np.float64(37.43360205024647),\n",
       "  np.float64(34.8427538966295),\n",
       "  np.float64(21.254294531115182),\n",
       "  np.float64(11.901108808012458),\n",
       "  np.float64(26.804295915673904),\n",
       "  np.float64(14.81065954965055),\n",
       "  np.float64(17.754931639462622),\n",
       "  np.float64(33.23224230276304),\n",
       "  np.float64(23.716241197846134),\n",
       "  np.float64(88.83856865873982),\n",
       "  np.float64(66.28742740042954),\n",
       "  np.float64(48.085285178320085),\n",
       "  np.float64(40.6735400819494),\n",
       "  np.float64(17.71703538400654),\n",
       "  np.float64(53.586521434760556),\n",
       "  np.float64(19.678098600379307),\n",
       "  np.float64(80.01127748031737),\n",
       "  np.float64(51.01680339725353),\n",
       "  np.float64(24.111655715184174),\n",
       "  np.float64(42.92646339325337),\n",
       "  np.float64(44.3856887277014),\n",
       "  np.float64(18.097706970950558),\n",
       "  np.float64(46.87970545503599),\n",
       "  np.float64(39.39566728916253),\n",
       "  np.float64(44.677194811572626),\n",
       "  np.float64(52.06360876882731),\n",
       "  np.float64(35.909316361947965),\n",
       "  np.float64(36.71003350599634),\n",
       "  np.float64(50.94157338631976),\n",
       "  np.float64(54.5128019174089),\n",
       "  np.float64(43.68473951265035),\n",
       "  np.float64(14.814077996525763),\n",
       "  np.float64(34.99612693951664),\n",
       "  np.float64(36.105453813131675),\n",
       "  np.float64(43.19296193366796),\n",
       "  np.float64(82.36400074626789),\n",
       "  np.float64(26.46334879755873),\n",
       "  np.float64(36.028719747055106),\n",
       "  np.float64(21.752543075186704),\n",
       "  np.float64(23.66569947243631),\n",
       "  np.float64(26.24030441943168),\n",
       "  np.float64(51.987430234432836),\n",
       "  np.float64(38.68327294619467),\n",
       "  np.float64(27.90502328673107),\n",
       "  np.float64(50.871657041533915),\n",
       "  np.float64(32.24373451271779),\n",
       "  np.float64(58.4087298570502),\n",
       "  np.float64(40.07701036919897),\n",
       "  np.float64(12.642445128997476),\n",
       "  np.float64(87.31136764092125),\n",
       "  np.float64(28.683685986654545),\n",
       "  np.float64(13.829150562521402),\n",
       "  np.float64(47.65506949717129),\n",
       "  np.float64(31.22277929535375),\n",
       "  np.float64(23.867652884283025),\n",
       "  np.float64(26.96879095806564),\n",
       "  np.float64(14.384783465693227),\n",
       "  np.float64(83.10160500635743),\n",
       "  np.float64(76.65265340375433),\n",
       "  np.float64(90.03775647188245),\n",
       "  np.float64(36.663907429352086),\n",
       "  np.float64(11.531796024679318),\n",
       "  np.float64(31.23869648625459),\n",
       "  np.float64(25.52723321074951),\n",
       "  np.float64(31.232387293493975),\n",
       "  np.float64(19.601634653320502),\n",
       "  np.float64(35.75566992630453),\n",
       "  np.float64(53.11728665458988),\n",
       "  np.float64(56.35391796832826),\n",
       "  np.float64(38.51103498732579),\n",
       "  np.float64(19.57810122843678),\n",
       "  np.float64(32.901679635736215),\n",
       "  np.float64(19.635380750777994),\n",
       "  np.float64(23.1523371490811),\n",
       "  np.float64(87.56862189684249),\n",
       "  np.float64(9.69727177661563),\n",
       "  np.float64(9.885270317923563),\n",
       "  np.float64(17.068630412949165),\n",
       "  np.float64(62.87752695876467),\n",
       "  np.float64(49.455072079221225),\n",
       "  np.float64(73.50534278939116),\n",
       "  np.float64(41.438230123844505),\n",
       "  np.float64(42.35806196201661),\n",
       "  np.float64(16.30749305712915),\n",
       "  np.float64(33.668308451704625),\n",
       "  np.float64(15.043417165421413),\n",
       "  np.float64(37.266289155063355),\n",
       "  np.float64(26.68773738896794),\n",
       "  np.float64(28.224724535305818),\n",
       "  np.float64(19.331905859189355),\n",
       "  np.float64(23.007154167584385),\n",
       "  np.float64(27.297978704999842),\n",
       "  np.float64(41.105977409823616),\n",
       "  np.float64(24.037967253409324),\n",
       "  np.float64(28.09985258786017),\n",
       "  np.float64(29.218699981636895),\n",
       "  np.float64(27.645865391463595),\n",
       "  np.float64(38.06183782119814),\n",
       "  np.float64(37.078723337760685),\n",
       "  np.float64(49.71724526851299),\n",
       "  np.float64(42.792146111808144),\n",
       "  np.float64(47.61807827222607),\n",
       "  np.float64(31.626905196983973),\n",
       "  np.float64(72.81805414475534),\n",
       "  np.float64(28.759807984625844),\n",
       "  np.float64(35.012206654020204),\n",
       "  np.float64(29.337746910074376),\n",
       "  np.float64(36.7047815851811),\n",
       "  np.float64(43.78036460397961),\n",
       "  np.float64(25.995552857865043),\n",
       "  np.float64(42.09013891491975),\n",
       "  np.float64(43.58140091305667),\n",
       "  np.float64(41.7385879956735),\n",
       "  np.float64(57.38594758890528),\n",
       "  np.float64(34.29301835883094),\n",
       "  np.float64(54.08048570393451),\n",
       "  np.float64(86.27771004069307),\n",
       "  np.float64(48.29606161381906),\n",
       "  np.float64(17.61945484519265),\n",
       "  np.float64(31.504523405446633),\n",
       "  np.float64(46.19507301371413),\n",
       "  np.float64(25.18054684624511),\n",
       "  np.float64(56.6167155515356),\n",
       "  np.float64(69.94350914147272),\n",
       "  np.float64(27.82526301231477),\n",
       "  np.float64(73.27953729435364),\n",
       "  np.float64(33.814098193690704),\n",
       "  np.float64(30.71889855094444),\n",
       "  np.float64(112.59501057593081),\n",
       "  np.float64(21.747233771665115),\n",
       "  np.float64(46.71024028668901),\n",
       "  np.float64(18.27314002780022),\n",
       "  np.float64(30.15131361543288),\n",
       "  np.float64(37.301371181849596),\n",
       "  np.float64(40.6902962458655),\n",
       "  np.float64(28.47968794409663),\n",
       "  np.float64(19.083005076749252),\n",
       "  np.float64(37.5083625626841),\n",
       "  np.float64(28.344966556369663),\n",
       "  np.float64(26.087423926845304),\n",
       "  np.float64(35.47883647069925),\n",
       "  np.float64(18.392737704903173),\n",
       "  np.float64(10.865738982489658),\n",
       "  np.float64(23.157690475173013),\n",
       "  np.float64(26.65034678310032),\n",
       "  np.float64(31.555587950745387),\n",
       "  np.float64(79.56634600598144),\n",
       "  np.float64(22.000765750777486),\n",
       "  np.float64(16.055946128966315),\n",
       "  np.float64(43.65268380308583),\n",
       "  np.float64(30.855128210655934),\n",
       "  np.float64(15.167871018323604),\n",
       "  np.float64(52.94879421624076),\n",
       "  np.float64(10.790538167091755),\n",
       "  np.float64(14.94750101285411),\n",
       "  np.float64(44.680056555643965),\n",
       "  np.float64(46.96970553512594),\n",
       "  np.float64(84.94113172205599),\n",
       "  np.float64(56.9235319478675),\n",
       "  np.float64(29.489745753205163),\n",
       "  np.float64(12.527492218117962),\n",
       "  np.float64(17.017329073991533),\n",
       "  np.float64(28.49350221598657),\n",
       "  np.float64(14.912635604081743),\n",
       "  np.float64(11.899542345164196),\n",
       "  np.float64(14.214582660042325),\n",
       "  np.float64(27.071589606709974),\n",
       "  np.float64(22.46497395959663),\n",
       "  np.float64(50.00148465552964),\n",
       "  np.float64(32.200845188639235),\n",
       "  np.float64(14.156782851647074),\n",
       "  np.float64(22.005781800712988),\n",
       "  np.float64(29.114818200436893),\n",
       "  np.float64(65.75869331472316),\n",
       "  np.float64(29.576736467271253),\n",
       "  np.float64(14.4746040605681),\n",
       "  np.float64(30.618303370781295),\n",
       "  np.float64(40.13155507093304),\n",
       "  np.float64(32.294500579512),\n",
       "  np.float64(37.986963571930474),\n",
       "  np.float64(26.210158603159698),\n",
       "  np.float64(31.461858104961788),\n",
       "  np.float64(39.50038305800921),\n",
       "  np.float64(49.01950858791964),\n",
       "  np.float64(39.908246647663525),\n",
       "  np.float64(29.223074243739717),\n",
       "  np.float64(29.75789907300739),\n",
       "  np.float64(47.43855112070861),\n",
       "  np.float64(55.32142355874799),\n",
       "  np.float64(27.304825099799128),\n",
       "  np.float64(33.218500267649375),\n",
       "  np.float64(31.880832594955752),\n",
       "  np.float64(21.304066751018187),\n",
       "  np.float64(42.85774602967944),\n",
       "  np.float64(25.589668091374197),\n",
       "  np.float64(33.518224081865945),\n",
       "  np.float64(19.33173447614471),\n",
       "  np.float64(51.28064663153766),\n",
       "  np.float64(35.29061395158371),\n",
       "  np.float64(35.39861354064973),\n",
       "  np.float64(11.735972259144784),\n",
       "  np.float64(29.519196532859304),\n",
       "  np.float64(11.801842537424319),\n",
       "  np.float64(33.94528957608915),\n",
       "  np.float64(34.52695024627553),\n",
       "  np.float64(29.268878936868727),\n",
       "  np.float64(113.82328803906559),\n",
       "  np.float64(27.860212782655452),\n",
       "  np.float64(46.993502670150676),\n",
       "  np.float64(47.608084342852614),\n",
       "  np.float64(28.224023789643187),\n",
       "  np.float64(36.95686914280482),\n",
       "  np.float64(43.333823801221094),\n",
       "  np.float64(9.405362090187008),\n",
       "  np.float64(99.61358075171104),\n",
       "  np.float64(15.680207414569068),\n",
       "  np.float64(11.221612764019596),\n",
       "  np.float64(22.039030083434763),\n",
       "  np.float64(41.00697120892903),\n",
       "  np.float64(20.057925792198706),\n",
       "  np.float64(101.76333949775797),\n",
       "  np.float64(62.99527414213558),\n",
       "  np.float64(34.41622189032327),\n",
       "  np.float64(31.13356882172345),\n",
       "  np.float64(31.645404273776943),\n",
       "  np.float64(46.720968286759685),\n",
       "  np.float64(31.342012313056298),\n",
       "  np.float64(49.985247971370285),\n",
       "  np.float64(24.24295873116977),\n",
       "  np.float64(42.023313462951585),\n",
       "  np.float64(37.78835715415059),\n",
       "  np.float64(37.5046224033426),\n",
       "  np.float64(39.62468373727888),\n",
       "  np.float64(10.931544696843993),\n",
       "  np.float64(56.900442730946345),\n",
       "  np.float64(20.222939955773136),\n",
       "  np.float64(55.31683638572867),\n",
       "  np.float64(57.4392603521481),\n",
       "  np.float64(22.849346374393317),\n",
       "  np.float64(32.13176877371403),\n",
       "  np.float64(17.293375471304397),\n",
       "  np.float64(30.246518756889763),\n",
       "  np.float64(45.653450499803704),\n",
       "  np.float64(58.24312441864846),\n",
       "  np.float64(32.48666945773685),\n",
       "  np.float64(47.12646296483941),\n",
       "  np.float64(35.04378871469366),\n",
       "  np.float64(33.715432104914726),\n",
       "  np.float64(40.9936432484043),\n",
       "  np.float64(37.17162214999609),\n",
       "  np.float64(25.46982156850699),\n",
       "  np.float64(82.25637736162197),\n",
       "  np.float64(36.449122244515515),\n",
       "  np.float64(38.64357154316444),\n",
       "  np.float64(32.79872191176143),\n",
       "  np.float64(15.580354439198716),\n",
       "  np.float64(11.46484749376891),\n",
       "  np.float64(29.92566170859224),\n",
       "  np.float64(29.15275065955523),\n",
       "  np.float64(28.007835353237496),\n",
       "  np.float64(9.766070126678201),\n",
       "  np.float64(25.201928426330444),\n",
       "  np.float64(13.86251551588731),\n",
       "  np.float64(46.90488114179807),\n",
       "  np.float64(54.11310435855246),\n",
       "  np.float64(42.21739037781323),\n",
       "  np.float64(50.66251556778563),\n",
       "  np.float64(46.70321283601683),\n",
       "  np.float64(33.706915443139074),\n",
       "  np.float64(25.860279503919543),\n",
       "  np.float64(41.78275631930064),\n",
       "  np.float64(60.66076380392189),\n",
       "  np.float64(43.94081905723346),\n",
       "  np.float64(41.08500530404479),\n",
       "  np.float64(30.529738462213334),\n",
       "  np.float64(40.09326480364795),\n",
       "  np.float64(36.73600243675759),\n",
       "  np.float64(29.80833611754733),\n",
       "  np.float64(25.013800677370465),\n",
       "  np.float64(37.32404740854672),\n",
       "  np.float64(31.55291577713741),\n",
       "  np.float64(48.03329400387734),\n",
       "  np.float64(32.89662906723408),\n",
       "  np.float64(28.92393275966789),\n",
       "  np.float64(23.72358476355015),\n",
       "  np.float64(17.48478071156157),\n",
       "  np.float64(76.52943342268514),\n",
       "  np.float64(92.47796164259547),\n",
       "  np.float64(79.15430345756509),\n",
       "  np.float64(45.481083402919765),\n",
       "  np.float64(32.51389040752073),\n",
       "  np.float64(69.19611626024515),\n",
       "  np.float64(24.14240278488075),\n",
       "  np.float64(31.397414211105634),\n",
       "  np.float64(30.983459528485483),\n",
       "  np.float64(27.454679079369598),\n",
       "  np.float64(20.08919934660743),\n",
       "  np.float64(23.938698739166597),\n",
       "  np.float64(52.71270284322686),\n",
       "  np.float64(12.054607294409907),\n",
       "  np.float64(12.9162947610466),\n",
       "  np.float64(51.920893447309226),\n",
       "  np.float64(34.51897385304209),\n",
       "  np.float64(30.982670088185404),\n",
       "  np.float64(41.18215385895882),\n",
       "  np.float64(67.24804655361821),\n",
       "  np.float64(17.084426320098842),\n",
       "  np.float64(38.25587916089784),\n",
       "  np.float64(39.32782685273707),\n",
       "  np.float64(32.72967974658284),\n",
       "  np.float64(38.04206458747769),\n",
       "  np.float64(11.744787512451392),\n",
       "  np.float64(48.228170029426366),\n",
       "  np.float64(25.386434488582513),\n",
       "  np.float64(36.777261075908136),\n",
       "  np.float64(44.68506275743186),\n",
       "  np.float64(70.40065951705375),\n",
       "  np.float64(27.36948276545469),\n",
       "  np.float64(13.473892505351778),\n",
       "  np.float64(31.470633579237298),\n",
       "  np.float64(44.64441135679103),\n",
       "  np.float64(19.268008700756937),\n",
       "  np.float64(27.003168133091428),\n",
       "  np.float64(37.187499767857126),\n",
       "  np.float64(40.40327074533096),\n",
       "  np.float64(47.8084702345331),\n",
       "  np.float64(15.030683185280207),\n",
       "  np.float64(33.04915098505253),\n",
       "  np.float64(34.94623381805129),\n",
       "  np.float64(58.73654988410066),\n",
       "  np.float64(56.67774614985648),\n",
       "  np.float64(22.52463288168455),\n",
       "  np.float64(25.948172001288),\n",
       "  np.float64(37.447475102974906),\n",
       "  np.float64(39.81940938276159),\n",
       "  np.float64(20.25034144761718),\n",
       "  np.float64(32.08255311731543),\n",
       "  np.float64(53.09244118588682),\n",
       "  np.float64(37.30028240849126),\n",
       "  np.float64(65.91514603119272),\n",
       "  np.float64(54.630940938407186),\n",
       "  np.float64(39.92159512519022),\n",
       "  np.float64(39.37686456686165),\n",
       "  np.float64(47.5655779833368),\n",
       "  np.float64(31.343939869560373),\n",
       "  np.float64(25.461535470036978),\n",
       "  np.float64(21.421222410954663),\n",
       "  np.float64(31.286403492085412),\n",
       "  np.float64(29.153642913376867),\n",
       "  np.float64(47.28327967949301),\n",
       "  np.float64(24.101084278770525),\n",
       "  np.float64(60.509339016461496),\n",
       "  np.float64(16.954515648636445),\n",
       "  np.float64(36.89855175030203),\n",
       "  np.float64(32.09311777142347),\n",
       "  np.float64(26.772228824388872),\n",
       "  np.float64(15.523789002754176),\n",
       "  np.float64(51.031086117137455),\n",
       "  np.float64(44.05359755946564),\n",
       "  np.float64(16.414116380937074),\n",
       "  np.float64(26.787746480906737),\n",
       "  np.float64(40.77904666700756),\n",
       "  np.float64(18.801614585469906),\n",
       "  np.float64(48.45783000180234),\n",
       "  np.float64(22.265852379515334),\n",
       "  np.float64(25.920237874635944),\n",
       "  np.float64(62.03960324893842),\n",
       "  np.float64(52.14874009598994),\n",
       "  np.float64(22.19767342677875),\n",
       "  np.float64(33.00034054570998),\n",
       "  np.float64(37.31577295392224),\n",
       "  np.float64(85.18430439721598),\n",
       "  np.float64(33.27650275681601),\n",
       "  np.float64(78.8591827851744),\n",
       "  np.float64(36.518079277233454),\n",
       "  np.float64(49.32251211787079),\n",
       "  np.float64(31.99468814934031),\n",
       "  np.float64(21.543691102408303),\n",
       "  np.float64(12.752287443699124),\n",
       "  np.float64(14.457633279661627),\n",
       "  np.float64(38.98899318551323),\n",
       "  np.float64(45.07083043319097),\n",
       "  np.float64(29.87996955677044),\n",
       "  np.float64(34.70700591739354),\n",
       "  np.float64(41.47147626121967),\n",
       "  np.float64(32.86101895554784),\n",
       "  np.float64(21.377939453650267),\n",
       "  np.float64(44.25867916166865),\n",
       "  np.float64(36.294070386044446),\n",
       "  np.float64(38.888810715532216),\n",
       "  np.float64(38.09744492818203),\n",
       "  np.float64(50.71319371857448),\n",
       "  np.float64(27.817847695700497),\n",
       "  np.float64(67.18857422226634),\n",
       "  np.float64(29.50978888621745),\n",
       "  np.float64(39.0359189356563),\n",
       "  np.float64(22.220261367208316),\n",
       "  np.float64(41.1322843566138),\n",
       "  np.float64(45.79343371193214),\n",
       "  np.float64(68.19682380071914),\n",
       "  np.float64(33.05018882567543),\n",
       "  np.float64(55.200517580449585),\n",
       "  np.float64(35.709062795169444),\n",
       "  np.float64(82.45846437703676),\n",
       "  np.float64(41.799082658421554),\n",
       "  np.float64(54.31122425947278),\n",
       "  np.float64(16.965731607968543),\n",
       "  np.float64(17.44120912556797),\n",
       "  np.float64(53.532465941396424),\n",
       "  np.float64(40.14119277023526),\n",
       "  np.float64(18.633707194832365),\n",
       "  np.float64(77.33342177296986),\n",
       "  np.float64(48.439550798630904),\n",
       "  np.float64(18.85041647151205),\n",
       "  np.float64(57.7646054180689),\n",
       "  np.float64(35.55790149423901),\n",
       "  np.float64(51.05576358218292),\n",
       "  np.float64(50.68518787712809),\n",
       "  np.float64(26.80413114655529),\n",
       "  np.float64(13.16444474710789),\n",
       "  np.float64(31.55408222584782),\n",
       "  np.float64(37.62432037567137),\n",
       "  np.float64(41.227892103058494),\n",
       "  np.float64(52.14113038774609),\n",
       "  np.float64(30.812182597360167),\n",
       "  np.float64(44.44068074316365),\n",
       "  np.float64(44.481668594213666),\n",
       "  np.float64(20.767116502745974),\n",
       "  np.float64(21.008879587296253),\n",
       "  np.float64(32.98744779690197),\n",
       "  np.float64(19.84826776033025),\n",
       "  np.float64(53.274929624866274),\n",
       "  np.float64(31.817338302961065),\n",
       "  np.float64(48.12709970674409),\n",
       "  np.float64(37.099074474800624),\n",
       "  np.float64(37.79315246269693),\n",
       "  np.float64(20.352019724820998),\n",
       "  np.float64(28.618824752911767),\n",
       "  np.float64(24.63837329452992),\n",
       "  np.float64(55.2422946952716),\n",
       "  np.float64(32.79509768582524),\n",
       "  np.float64(37.48247174937219),\n",
       "  np.float64(47.12869879939293),\n",
       "  np.float64(31.838946949168967),\n",
       "  np.float64(62.18102874216789),\n",
       "  np.float64(20.840342536446364),\n",
       "  np.float64(37.61257132789466),\n",
       "  np.float64(47.27892189735894),\n",
       "  np.float64(52.12666736691086),\n",
       "  np.float64(40.363479630079),\n",
       "  np.float64(32.5839356978527),\n",
       "  np.float64(57.45761286805186),\n",
       "  np.float64(35.5552176874134),\n",
       "  np.float64(52.337560491513315),\n",
       "  np.float64(18.86287482731553),\n",
       "  np.float64(21.821491989160023),\n",
       "  np.float64(90.41221705828386),\n",
       "  np.float64(50.288287422839225),\n",
       "  np.float64(41.00713720177219),\n",
       "  np.float64(33.58510223894408),\n",
       "  np.float64(61.736738013081926),\n",
       "  np.float64(37.292765437860766),\n",
       "  np.float64(31.21055942526165),\n",
       "  np.float64(27.415774529109225),\n",
       "  np.float64(61.15916225566724),\n",
       "  np.float64(42.33633994290289),\n",
       "  np.float64(19.81791441351184),\n",
       "  np.float64(55.56581607867101),\n",
       "  np.float64(30.649321050509045),\n",
       "  np.float64(28.32712505959064),\n",
       "  np.float64(41.097248503464904),\n",
       "  np.float64(29.21217072698735),\n",
       "  np.float64(30.674643894601488),\n",
       "  np.float64(38.06789867355865),\n",
       "  np.float64(10.648744687509978),\n",
       "  np.float64(39.25417144878051),\n",
       "  np.float64(64.93578401510398),\n",
       "  np.float64(35.2488941802588),\n",
       "  np.float64(34.32965399641903),\n",
       "  np.float64(46.21157281303604),\n",
       "  np.float64(39.68221695045003),\n",
       "  np.float64(9.981672249109664),\n",
       "  np.float64(36.250782425516825),\n",
       "  np.float64(60.12454974357486),\n",
       "  np.float64(43.28535371783033),\n",
       "  np.float64(24.804889719588317),\n",
       "  np.float64(96.3918888632376),\n",
       "  np.float64(11.140884223354998),\n",
       "  np.float64(52.56637473346563),\n",
       "  np.float64(18.64725102047595),\n",
       "  np.float64(37.83148966242786),\n",
       "  np.float64(16.43792816245356),\n",
       "  np.float64(15.410992378234162),\n",
       "  np.float64(57.06723431427546),\n",
       "  np.float64(34.515495039261545),\n",
       "  np.float64(31.846097343852875),\n",
       "  np.float64(43.84639502403332),\n",
       "  np.float64(42.10545751686546),\n",
       "  np.float64(53.689428397971966),\n",
       "  np.float64(58.296212820370386),\n",
       "  np.float64(21.821754845108693),\n",
       "  np.float64(18.129813403780748),\n",
       "  np.float64(33.69660165018311),\n",
       "  np.float64(29.03316319346199),\n",
       "  np.float64(60.20311220670204),\n",
       "  np.float64(17.23429432856478),\n",
       "  np.float64(35.77804319980404),\n",
       "  np.float64(36.265588525241746),\n",
       "  np.float64(35.87947025969158),\n",
       "  np.float64(29.7782335289966),\n",
       "  np.float64(89.85900252029326),\n",
       "  np.float64(40.02429903669573),\n",
       "  np.float64(47.52790109276265),\n",
       "  np.float64(29.358394855410143),\n",
       "  np.float64(25.57252750626552),\n",
       "  np.float64(55.950738255525934),\n",
       "  np.float64(36.691684248018156),\n",
       "  np.float64(29.753263535950385),\n",
       "  np.float64(42.556459692537864),\n",
       "  np.float64(22.69982205692254),\n",
       "  np.float64(11.788189920871908),\n",
       "  np.float64(40.85642006088788),\n",
       "  np.float64(11.136250133593528),\n",
       "  np.float64(36.54693901389404),\n",
       "  np.float64(41.81056935665276),\n",
       "  np.float64(75.25753308998728),\n",
       "  np.float64(33.09358807610168),\n",
       "  np.float64(41.749174856650654),\n",
       "  np.float64(44.45962334273231),\n",
       "  np.float64(39.02343425018161),\n",
       "  np.float64(20.53269235560112),\n",
       "  np.float64(67.78150340096968),\n",
       "  np.float64(25.574539835251866),\n",
       "  np.float64(23.75251240443011),\n",
       "  np.float64(41.880664582845476),\n",
       "  np.float64(38.38137487277646),\n",
       "  np.float64(47.30863506187807),\n",
       "  np.float64(30.27172815567489),\n",
       "  np.float64(48.82957883293304),\n",
       "  np.float64(40.64978528661747),\n",
       "  np.float64(13.828011280305994),\n",
       "  np.float64(30.713993733665006),\n",
       "  np.float64(26.24039326500016),\n",
       "  np.float64(16.170158362483125),\n",
       "  np.float64(11.653174500468076),\n",
       "  np.float64(16.57296657383232),\n",
       "  np.float64(52.84590691528577),\n",
       "  np.float64(46.293592264245845),\n",
       "  np.float64(49.45898613303162),\n",
       "  np.float64(10.72567064738042),\n",
       "  np.float64(29.413980166235003),\n",
       "  np.float64(18.23140788705321),\n",
       "  np.float64(27.74751950022842),\n",
       "  np.float64(45.54308273355759),\n",
       "  np.float64(33.86873430861095),\n",
       "  np.float64(46.39379354482916),\n",
       "  np.float64(29.684224347404513),\n",
       "  np.float64(14.606208020642617),\n",
       "  np.float64(16.791730014793032),\n",
       "  np.float64(32.930932107393424),\n",
       "  np.float64(46.17266450569324),\n",
       "  np.float64(38.99185033340596),\n",
       "  np.float64(94.88193560108294),\n",
       "  np.float64(43.141746921319836),\n",
       "  np.float64(45.564539311490414),\n",
       "  np.float64(37.43148794309686),\n",
       "  np.float64(27.83616594754359),\n",
       "  np.float64(39.62327521069753),\n",
       "  np.float64(29.474564687933903),\n",
       "  np.float64(46.770519329305266),\n",
       "  np.float64(23.758408172977983),\n",
       "  np.float64(13.817326927952273),\n",
       "  np.float64(44.55517275843052),\n",
       "  np.float64(85.59527501632057),\n",
       "  np.float64(29.98600063548994),\n",
       "  np.float64(49.86306078574311),\n",
       "  np.float64(15.733916454013045),\n",
       "  np.float64(29.366493899565352),\n",
       "  np.float64(37.85026167523448),\n",
       "  np.float64(31.43345641648756),\n",
       "  np.float64(21.1647802779828),\n",
       "  np.float64(39.89046537961041),\n",
       "  np.float64(16.9115373854801),\n",
       "  np.float64(42.675812999156655),\n",
       "  np.float64(113.97237911239671),\n",
       "  np.float64(89.77983474455645),\n",
       "  np.float64(33.913883818904445),\n",
       "  np.float64(10.479923210609238),\n",
       "  np.float64(36.9123331351615),\n",
       "  np.float64(53.65906977880513),\n",
       "  np.float64(57.31568549378719),\n",
       "  np.float64(41.594741494283554),\n",
       "  np.float64(25.604590941393244),\n",
       "  np.float64(67.87929813426643),\n",
       "  np.float64(26.492720988515316),\n",
       "  np.float64(16.559853299641215),\n",
       "  np.float64(82.94298478017113),\n",
       "  np.float64(12.421724238365),\n",
       "  np.float64(10.427441371186047),\n",
       "  np.float64(23.511703724830998),\n",
       "  np.float64(49.746238500171884),\n",
       "  np.float64(44.849531335427784),\n",
       "  np.float64(75.27774322883239),\n",
       "  np.float64(25.934609397662985),\n",
       "  np.float64(62.26856766782913),\n",
       "  np.float64(42.24376017488233),\n",
       "  np.float64(29.40491762238175),\n",
       "  np.float64(26.756178850822177),\n",
       "  np.float64(65.09032821417492),\n",
       "  np.float64(36.86264208203254),\n",
       "  np.float64(58.70329609701989),\n",
       "  np.float64(50.33240899150889),\n",
       "  np.float64(31.009709953972465),\n",
       "  np.float64(36.93452335050794),\n",
       "  np.float64(49.41786426017663),\n",
       "  np.float64(13.231782370963534),\n",
       "  np.float64(50.304981120379196),\n",
       "  np.float64(38.306629905273944),\n",
       "  np.float64(53.43024506708065),\n",
       "  np.float64(45.928880749055104),\n",
       "  np.float64(24.438730851082042),\n",
       "  np.float64(17.37102579672363),\n",
       "  np.float64(35.902759895900914),\n",
       "  np.float64(49.1532662588914),\n",
       "  np.float64(40.87476534857227),\n",
       "  np.float64(33.80657955453414),\n",
       "  np.float64(25.23078337050788),\n",
       "  np.float64(21.879025832626123),\n",
       "  np.float64(51.35461944730263),\n",
       "  np.float64(29.476923213850057),\n",
       "  np.float64(42.219193192121246),\n",
       "  np.float64(32.48475093254932),\n",
       "  np.float64(44.758950576172175),\n",
       "  np.float64(31.971398780948263),\n",
       "  np.float64(72.99716136179478),\n",
       "  np.float64(38.815225543452506),\n",
       "  np.float64(15.530160669878143),\n",
       "  np.float64(63.518150886983335),\n",
       "  np.float64(77.25389699179851),\n",
       "  np.float64(39.44524403036118),\n",
       "  np.float64(36.31117985299462),\n",
       "  np.float64(45.70557145077639),\n",
       "  np.float64(26.258148489923716),\n",
       "  np.float64(23.896707174282756),\n",
       "  np.float64(56.75535075107889),\n",
       "  np.float64(30.61514949176423),\n",
       "  np.float64(51.41981518664585),\n",
       "  np.float64(60.39253633667005),\n",
       "  np.float64(29.57326208461761),\n",
       "  np.float64(47.97422182928795),\n",
       "  np.float64(27.340216985901716),\n",
       "  np.float64(38.38852320436607),\n",
       "  np.float64(45.284621667581234),\n",
       "  np.float64(48.28006840912241),\n",
       "  np.float64(22.46171329132594),\n",
       "  np.float64(27.66723530706767),\n",
       "  np.float64(29.030396079703763),\n",
       "  np.float64(34.06749511926799),\n",
       "  np.float64(52.83278096363917),\n",
       "  np.float64(35.67402221990288),\n",
       "  np.float64(50.913628427647915),\n",
       "  np.float64(18.687605688379854),\n",
       "  np.float64(32.86731278515603),\n",
       "  np.float64(21.7407912460863),\n",
       "  np.float64(63.63421788040624),\n",
       "  np.float64(39.43237288423461),\n",
       "  np.float64(40.27772706079703),\n",
       "  np.float64(27.037162879009458),\n",
       "  np.float64(52.6578073387444),\n",
       "  np.float64(37.49237634715208),\n",
       "  np.float64(70.70283691299687),\n",
       "  np.float64(21.665471884258206),\n",
       "  np.float64(19.878721267698293),\n",
       "  np.float64(9.157370722071763),\n",
       "  np.float64(57.4822358758768),\n",
       "  np.float64(62.248961688277475),\n",
       "  np.float64(81.2030780098157),\n",
       "  np.float64(68.26634380454979),\n",
       "  np.float64(24.28477135182513),\n",
       "  np.float64(64.14135407283972),\n",
       "  np.float64(28.09682297628626),\n",
       "  np.float64(54.398124270513655),\n",
       "  np.float64(15.465247449553996),\n",
       "  np.float64(30.9949001161135),\n",
       "  np.float64(28.714333241589692),\n",
       "  np.float64(35.44928568842596),\n",
       "  np.float64(25.944865002744592),\n",
       "  np.float64(24.034083919312593),\n",
       "  np.float64(53.48127373523889),\n",
       "  np.float64(13.039842088245859),\n",
       "  np.float64(90.53099786762671),\n",
       "  np.float64(18.688494121510228),\n",
       "  np.float64(27.529813828104768),\n",
       "  np.float64(26.88966309853184),\n",
       "  np.float64(90.82378310183121),\n",
       "  np.float64(19.40706277691581),\n",
       "  np.float64(28.245274216929904),\n",
       "  np.float64(112.51795532391978),\n",
       "  np.float64(24.620430225745924),\n",
       "  np.float64(48.95652007407415),\n",
       "  np.float64(39.890369556035715),\n",
       "  np.float64(34.11919722725374),\n",
       "  np.float64(48.67729045090964),\n",
       "  np.float64(43.7076306369956),\n",
       "  np.float64(29.368103019297404),\n",
       "  np.float64(27.407580927534955),\n",
       "  np.float64(29.510636614332988),\n",
       "  np.float64(22.71522166519966),\n",
       "  np.float64(90.52400310773827),\n",
       "  np.float64(36.071146149380745),\n",
       "  np.float64(77.16252500450024),\n",
       "  np.float64(27.36873660335921),\n",
       "  np.float64(17.703413869164585),\n",
       "  np.float64(40.24475860111624),\n",
       "  np.float64(12.246508156476722),\n",
       "  np.float64(28.51560196756759),\n",
       "  np.float64(40.082884226052634),\n",
       "  np.float64(25.562273823057932),\n",
       "  np.float64(24.16231027907444),\n",
       "  np.float64(38.91359309899616),\n",
       "  np.float64(30.464906046018196),\n",
       "  np.float64(70.72088133142141),\n",
       "  np.float64(26.933296323051135),\n",
       "  np.float64(43.14581765354157),\n",
       "  np.float64(21.975009658040847),\n",
       "  np.float64(35.64053534774659),\n",
       "  np.float64(47.12157668102176),\n",
       "  np.float64(30.09448296833752),\n",
       "  np.float64(32.20334850587678),\n",
       "  np.float64(56.00531399617204),\n",
       "  np.float64(37.549253438959184),\n",
       "  np.float64(53.481843428875635),\n",
       "  np.float64(45.97247433059834),\n",
       "  ...]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.metrics import DTWMetric, GeoBLEUMetric, LPPMetric, MAEMetric\n",
    "\n",
    "# Instanciar métricas\n",
    "metrics_instances = [\n",
    "    LPPMetric(),\n",
    "    MAEMetric(),\n",
    "    GeoBLEUMetric(),\n",
    "    DTWMetric(),\n",
    "]\n",
    "# Todo Mirar el testloader a ver xq es que hay pocas targets  y verificar sis e estan creando todas las seciencias en el target\n",
    "# Evaluar métricas\n",
    "evaluate_metrics_with_masks(\n",
    "    model, test_loader, metrics_instances, scaler=global_scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo completo guardado correctamente en 'simple_nn_complete.pth'.\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model, \"../Data/Models/Simple_NN.pth\")\n",
    "# print(\"Modelo completo guardado correctamente en 'simple_nn_complete.pth'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
